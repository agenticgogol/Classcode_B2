{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfb1173e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import gradio as gr\n",
    "from typing import TypedDict, Any\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# --------------------\n",
    "# State & Cost Tracking\n",
    "# --------------------\n",
    "class AgentState(TypedDict):\n",
    "    messages: list\n",
    "    topic: str\n",
    "    research: str\n",
    "    synthesized: str\n",
    "    fact_checked: str\n",
    "    edited: str\n",
    "    summary: str\n",
    "    metrics: dict\n",
    "\n",
    "PRICES = {\n",
    "    \"gpt-4o-mini\": {\"input\": 0.00015 / 1000, \"output\": 0.0006 / 1000}\n",
    "}\n",
    "\n",
    "def estimate_tokens(text: str) -> int:\n",
    "    if not text:\n",
    "        return 0\n",
    "    return int(len(text.split()) * 1.3)\n",
    "\n",
    "def _extract_content(resp):\n",
    "    if resp is None:\n",
    "        return \"\"\n",
    "    if hasattr(resp, \"content\"):\n",
    "        return getattr(resp, \"content\") or \"\"\n",
    "    if isinstance(resp, dict) and \"content\" in resp:\n",
    "        return resp[\"content\"] or \"\"\n",
    "    return str(resp)\n",
    "\n",
    "# --------------------\n",
    "# Global LLM (set in setup tab)\n",
    "# --------------------\n",
    "llm = None\n",
    "\n",
    "def call_llm_with_metrics(agent_name, prompt, state):\n",
    "    global llm\n",
    "    start = time.time()\n",
    "    try:\n",
    "        resp = llm.invoke(prompt)\n",
    "    except Exception as e:\n",
    "        resp = None\n",
    "        print(f\"[ERROR] {agent_name} failed:\", e)\n",
    "    end = time.time()\n",
    "    content = _extract_content(resp)\n",
    "\n",
    "    in_tokens = estimate_tokens(prompt)\n",
    "    out_tokens = estimate_tokens(content)\n",
    "    model = getattr(llm, \"model_name\", \"gpt-4o-mini\")\n",
    "    pricing = PRICES.get(model, PRICES[\"gpt-4o-mini\"])\n",
    "    cost = in_tokens * pricing[\"input\"] + out_tokens * pricing[\"output\"]\n",
    "\n",
    "    state.setdefault(\"metrics\", {})[agent_name] = {\n",
    "        \"latency\": round(end - start, 2),\n",
    "        \"in_tokens\": in_tokens,\n",
    "        \"out_tokens\": out_tokens,\n",
    "        \"cost\": round(cost, 6),\n",
    "    }\n",
    "    return content\n",
    "\n",
    "# --------------------\n",
    "# Agents\n",
    "# --------------------\n",
    "def ResearchAgent(state: AgentState) -> AgentState:\n",
    "    prompt = f\"\"\"\n",
    "    You are a Research Agent.\n",
    "\n",
    "    Task: Gather relevant, high-quality information on the topic below.\n",
    "    - Cover definitions, background, current trends, and key debates.\n",
    "    - Include real-world applications or case studies if relevant.\n",
    "    - Present findings in a structured way (not an essay, not bullet-only).\n",
    "    - Keep it neutral and fact-rich.\n",
    "\n",
    "    Topic:\n",
    "    {state['topic']}\n",
    "    \"\"\"\n",
    "    state[\"research\"] = call_llm_with_metrics(\"ResearchAgent\", prompt, state)\n",
    "    state[\"messages\"].append(\"research_done\")\n",
    "    return state\n",
    "\n",
    "def SynthesizeAgent(state: AgentState) -> AgentState:\n",
    "    prompt = f\"\"\"\n",
    "    You are a Synthesis Agent.\n",
    "\n",
    "    Task: Combine the research findings into a **coherent draft article**.\n",
    "    - Weave information into a clear narrative.\n",
    "    - Avoid repetition; integrate overlapping points.\n",
    "    - Maintain a balanced, professional tone.\n",
    "    - Do not fact-check or edit here — just create a readable draft.\n",
    "\n",
    "    Research:\n",
    "    {state['research']}\n",
    "    \"\"\"\n",
    "    state[\"synthesized\"] = call_llm_with_metrics(\"SynthesizeAgent\", prompt, state)\n",
    "    state[\"messages\"].append(\"synthesize_done\")\n",
    "    return state\n",
    "\n",
    "\n",
    "def FactCheckAgent(state: AgentState) -> AgentState:\n",
    "    prompt = f\"\"\"\n",
    "    You are a Fact-Checking Agent.\n",
    "\n",
    "    Task: Review the following draft and ensure factual accuracy.\n",
    "    - Correct inaccuracies *inline*.\n",
    "    - If information is vague or incomplete, improve it with accurate detail.\n",
    "    - Do NOT output commentary like \"Accurate\" or \"Inaccurate.\"\n",
    "    - Do NOT ask the user questions.\n",
    "    - Just return a clean, factually correct draft article.\n",
    "\n",
    "    Draft:\n",
    "    {state['synthesized'] or state['research']}\n",
    "    \"\"\"\n",
    "    state[\"fact_checked\"] = call_llm_with_metrics(\"FactCheckAgent\", prompt, state)\n",
    "    state[\"messages\"].append(\"factcheck_done\")\n",
    "    return state\n",
    "\n",
    "\n",
    "def EditAgent(state: AgentState) -> AgentState:\n",
    "    prompt = f\"\"\"\n",
    "    You are an Editing Agent.\n",
    "\n",
    "    Task: Improve the readability, flow, and clarity of the following draft.\n",
    "    - Keep factual details intact.\n",
    "    - Make the text engaging and coherent.\n",
    "    - Do not shorten excessively; preserve important content.\n",
    "\n",
    "    Draft:\n",
    "    {state['fact_checked']}\n",
    "    \"\"\"\n",
    "    state[\"edited\"] = call_llm_with_metrics(\"EditAgent\", prompt, state)\n",
    "    state[\"messages\"].append(\"edit_done\")\n",
    "    return state\n",
    "\n",
    "\n",
    "def SummarizeAgent(state: AgentState) -> AgentState:\n",
    "    prompt = f\"\"\"\n",
    "    You are a Summarization Agent.\n",
    "\n",
    "    Task: Summarize the following article in **3–4 concise sentences**.\n",
    "    Focus on key ideas and implications. Avoid redundancy.\n",
    "\n",
    "    Article:\n",
    "    {state['edited']}\n",
    "    \"\"\"\n",
    "    state[\"summary\"] = call_llm_with_metrics(\"SummarizeAgent\", prompt, state)\n",
    "    state[\"messages\"].append(\"summarize_done\")\n",
    "    return state\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# Graph Builders\n",
    "# --------------------\n",
    "def build_single_agent_graph(llm_param):\n",
    "    workflow = StateGraph(AgentState)\n",
    "    def single_node(state: AgentState) -> AgentState:\n",
    "        start = time.time()\n",
    "        resp = llm_param.invoke(f\"Do research, synthesize, fact-check, edit, and summarize:\\n{state['topic']}\")\n",
    "        edited = _extract_content(resp)\n",
    "        summary_resp = llm_param.invoke(\"Summarize in 3 sentences:\\n\" + edited)\n",
    "        summary = _extract_content(summary_resp)\n",
    "        end = time.time()\n",
    "        in_tokens = estimate_tokens(state[\"topic\"])\n",
    "        out_tokens = estimate_tokens(edited + summary)\n",
    "        model = getattr(llm_param, \"model_name\", \"gpt-4o-mini\")\n",
    "        pricing = PRICES.get(model, PRICES[\"gpt-4o-mini\"])\n",
    "        cost = in_tokens * pricing[\"input\"] + out_tokens * pricing[\"output\"]\n",
    "        state[\"edited\"], state[\"summary\"] = edited, summary\n",
    "        state.setdefault(\"metrics\", {})[\"SingleAgent\"] = {\n",
    "            \"latency\": round(end - start, 2),\n",
    "            \"in_tokens\": in_tokens,\n",
    "            \"out_tokens\": out_tokens,\n",
    "            \"cost\": round(cost, 6),\n",
    "        }\n",
    "        return state\n",
    "    workflow.add_node(\"single\", single_node)\n",
    "    workflow.set_entry_point(\"single\")\n",
    "    workflow.add_edge(\"single\", END)\n",
    "    return workflow.compile()\n",
    "\n",
    "def build_sequential_agent_graph(llm_param):\n",
    "    wf = StateGraph(AgentState)\n",
    "    wf.add_node(\"research\", ResearchAgent)\n",
    "    wf.add_node(\"synthesize\", SynthesizeAgent)\n",
    "    wf.add_node(\"fact\", FactCheckAgent)\n",
    "    wf.add_node(\"edit\", EditAgent)\n",
    "    wf.add_node(\"summary\", SummarizeAgent)\n",
    "    wf.set_entry_point(\"research\")\n",
    "    wf.add_edge(\"research\", \"synthesize\")\n",
    "    wf.add_edge(\"synthesize\", \"fact\")\n",
    "    wf.add_edge(\"fact\", \"edit\")\n",
    "    wf.add_edge(\"edit\", \"summary\")\n",
    "    wf.add_edge(\"summary\", END)\n",
    "    return wf.compile()\n",
    "\n",
    "def build_parallel_agent_graph(llm_param):\n",
    "    wf = StateGraph(AgentState)\n",
    "    def parallel_stage(state: AgentState) -> AgentState:\n",
    "        synth_state, fact_state = state.copy(), state.copy()\n",
    "        with ThreadPoolExecutor(max_workers=2) as ex:\n",
    "            futures = {\n",
    "                ex.submit(SynthesizeAgent, synth_state): \"synth\",\n",
    "                ex.submit(FactCheckAgent, fact_state): \"fact\"\n",
    "            }\n",
    "            for fut in as_completed(futures):\n",
    "                res = fut.result()\n",
    "                if futures[fut] == \"synth\":\n",
    "                    state[\"synthesized\"] = res[\"synthesized\"]\n",
    "                else:\n",
    "                    state[\"fact_checked\"] = res[\"fact_checked\"]\n",
    "        return state\n",
    "    wf.add_node(\"research\", ResearchAgent)\n",
    "    wf.add_node(\"parallel\", parallel_stage)\n",
    "    wf.add_node(\"edit\", EditAgent)\n",
    "    wf.add_node(\"summary\", SummarizeAgent)\n",
    "    wf.set_entry_point(\"research\")\n",
    "    wf.add_edge(\"research\", \"parallel\")\n",
    "    wf.add_edge(\"parallel\", \"edit\")\n",
    "    wf.add_edge(\"edit\", \"summary\")\n",
    "    wf.add_edge(\"summary\", END)\n",
    "    return wf.compile()\n",
    "\n",
    "# --------------------\n",
    "# Runner\n",
    "# --------------------\n",
    "def run_workflow(graph, topic: str) -> dict:\n",
    "    init_state = {\"messages\": [], \"topic\": topic, \"research\": \"\", \"synthesized\": \"\", \"fact_checked\": \"\", \"edited\": \"\", \"summary\": \"\", \"metrics\": {}}\n",
    "    return graph.invoke(init_state)\n",
    "\n",
    "# --------------------\n",
    "# Setup\n",
    "# --------------------\n",
    "def setup_api_key(api_key: str):\n",
    "    global llm\n",
    "    if not api_key.strip():\n",
    "        return \"❌ No API key entered\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2, api_key=api_key.strip())\n",
    "    return \"✅ API key set successfully\"\n",
    "\n",
    "# --------------------\n",
    "# Content + Metrics\n",
    "# --------------------\n",
    "def generate_with_graph(graph, topic: str):\n",
    "    result = run_workflow(graph, topic)\n",
    "    content = result.get(\"edited\") or result.get(\"summary\") or \"(no content)\"\n",
    "    metrics = result.get(\"metrics\", {})\n",
    "    md = \"| Agent | Latency | In | Out | Cost |\\n|-------|---------|----|-----|------|\\n\"\n",
    "    for k, v in metrics.items():\n",
    "        md += f\"| {k} | {v['latency']}s | {v['in_tokens']} | {v['out_tokens']} | ${v['cost']:.6f} |\\n\"\n",
    "    return content, md\n",
    "\n",
    "# --------------------\n",
    "# Evaluation (LLM Judge)\n",
    "# --------------------\n",
    "def evaluate_outputs(single_out, seq_out, par_out):\n",
    "    global llm\n",
    "    judge_prompt = f\"\"\"You are a judge. Evaluate three outputs on accuracy, coherence, and conciseness.\n",
    "    \n",
    "    --- Single Agent ---\n",
    "    {single_out}\n",
    "    \n",
    "    --- Sequential Agents ---\n",
    "    {seq_out}\n",
    "    \n",
    "    --- Parallel Agents ---\n",
    "    {par_out}\n",
    "    \n",
    "    Give scores (1-10) for each and a short justification.\"\"\"\n",
    "    resp = llm.invoke(judge_prompt)\n",
    "    return _extract_content(resp)\n",
    "\n",
    "# --------------------\n",
    "# Gradio UI\n",
    "# --------------------\n",
    "with gr.Blocks(title=\"Multi-Agent Pipeline\") as app:\n",
    "    gr.Markdown(\"# 🔄 Multi-Agent Content Pipeline\")\n",
    "\n",
    "    with gr.Tab(\"Setup\"):\n",
    "        api_key_box = gr.Textbox(label=\"Enter OpenAI API Key\", type=\"password\")\n",
    "        setup_btn = gr.Button(\"Set API Key\")\n",
    "        setup_status = gr.Markdown()\n",
    "        setup_btn.click(setup_api_key, api_key_box, setup_status)\n",
    "\n",
    "    with gr.Tab(\"Single Agent\"):\n",
    "        topic1 = gr.Textbox(label=\"Topic\")\n",
    "        out1, metrics1 = gr.Markdown(), gr.Markdown()\n",
    "        gen1 = gr.Button(\"Generate (Single)\")\n",
    "        gen1.click(lambda t: generate_with_graph(build_single_agent_graph(llm), t), topic1, [out1, metrics1])\n",
    "\n",
    "    with gr.Tab(\"Sequential Agents\"):\n",
    "        topic2 = gr.Textbox(label=\"Topic\")\n",
    "        out2, metrics2 = gr.Markdown(), gr.Markdown()\n",
    "        gen2 = gr.Button(\"Generate (Sequential)\")\n",
    "        gen2.click(lambda t: generate_with_graph(build_sequential_agent_graph(llm), t), topic2, [out2, metrics2])\n",
    "\n",
    "    with gr.Tab(\"Parallel Agents\"):\n",
    "        topic3 = gr.Textbox(label=\"Topic\")\n",
    "        out3, metrics3 = gr.Markdown(), gr.Markdown()\n",
    "        gen3 = gr.Button(\"Generate (Parallel)\")\n",
    "        gen3.click(lambda t: generate_with_graph(build_parallel_agent_graph(llm), t), topic3, [out3, metrics3])\n",
    "\n",
    "    with gr.Tab(\"Evaluation Results\"):\n",
    "        eval_btn = gr.Button(\"Evaluate All\")\n",
    "        eval_out = gr.Markdown()\n",
    "        eval_btn.click(evaluate_outputs, [out1, out2, out3], eval_out)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2bc1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
