{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Al36oPEdl3YT"
      },
      "outputs": [],
      "source": [
        "# OBJECTIVE : a) Agent Delegation and hiearchy demo b) Parallely can multiple agents work c)Real World\n",
        "\n",
        "# Scenario1 :\n",
        "# A Startup wants to reseach the AI Chatbot market before launching their product.\n",
        "# The CEO delegates research to specialized agents who work in parallel and collaborate\n",
        "\n",
        "# Scenario2:\n",
        "# Financial Assistant Agent - Given a stock , it will tell whether this is the right time to enter into it\n",
        "# Financial Planner Agent - Given a individual and his current portfolio , can there be a goal based financial planning done\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q crewai crewai_tools langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpRmnd58m1o3",
        "outputId": "65a81766-fb97-40b3-e42b-ca603e160085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.3/423.3 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.8/719.8 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.3/211.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.5/155.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.8/35.8 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.0/363.0 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.9/131.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m786.2/786.2 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.3/242.3 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.0/98.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.1/213.1 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.4/295.4 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.3/337.3 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.6/229.6 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "transformers 4.56.1 requires tokenizers<=0.23.0,>=0.22.0, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "os.environ[\"OPENAI_MODEL_NAME\"] = \"gpt-4o-mini\"\n",
        "os.environ[\"SERPER_API_KEY\"] = \"\""
      ],
      "metadata": {
        "id": "oDbovpJPm4iS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew,Process\n",
        "from crewai_tools import ScrapeWebsiteTool, SerperDevTool\n",
        "search_tool = SerperDevTool()\n",
        "scrape_tool = ScrapeWebsiteTool()"
      ],
      "metadata": {
        "id": "wkAK-qAInENl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0150ac16-ffe7-4725-f3d1-081b65c21616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the market esearch crew\n",
        "from langchain_openai import ChatOpenAI\n",
        "llm = ChatOpenAI(model = \"gpt-4o-mini\",temperature = 0.1)"
      ],
      "metadata": {
        "id": "qXln6qNPyz3C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c64266b-8903-4d85-eed6-6a655881de65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CEO Agent - Orchestrates and delegates\n",
        "ceo_agent = Agent(\n",
        "    role=\"CEO & Strategic Overseer\",\n",
        "    goal = \"Coordinate market research efforts and synthesize insights for strategic decision making\",\n",
        "    backstory = \"\"\" You are a visionary CEO of an AI startup. you understand that  market research is cucial before launching your AI chatbot product.\n",
        "    You are excellent in delegating tasks to specialists and synthesizing their findings into actionable business strategy\n",
        "    \"\"\",\n",
        "    verbose = True,\n",
        "    allow_delegation = True,\n",
        "    llm = llm\n",
        "\n",
        ")\n",
        "\n",
        "# Market Research Agent - researches the market size and trends\n",
        "market_research_analyst = Agent(\n",
        "    role = \"Senior Market Research Analyst\",\n",
        "    goal = \"Analyze AI chatbot market and its growth trends and key market dynamics\",\n",
        "    backstory = \"\"\"You are a seasoned market research analyst with 10+ years of experience the technology market . You excel in finding reliable market data ,\n",
        "    analyzing the trends, and identifying market opprotunities and threats. You use web search extensively to gather current market data\n",
        "    \"\"\",\n",
        "    tools = [search_tool,scrape_tool],\n",
        "    verbose = True,\n",
        "    llm = llm\n",
        ")\n",
        "\n",
        "# Competitive Intellgence Analyst - analyzes the competitor\n",
        "competitive_analyst = Agent(\n",
        "    role = \"Senior Competitive Intellgence Specialist\",\n",
        "    goal = \"Identify and analyze ket competitors in the Ai chatbot market\",\n",
        "    backstory = \"\"\"You are a competitive intelligence expert who specializes in AI related product analysis. You are skilled at identifying both direct\n",
        "    and indirect competitors, analyze their pricing strategies and market positioning. You use web search extensively to gather competitive data.\n",
        "    \"\"\",\n",
        "    tools = [search_tool,scrape_tool],\n",
        "    verbose = True,\n",
        "    llm = llm\n",
        "\n",
        ")\n",
        "\n",
        "# Customer research specialist - Studies the target customer\n",
        "customer_researcher = Agent(\n",
        "    role = \"Customer Research specialist\",\n",
        "    goal = \"Research the AI chatbot target customer segments, their pain points and preferences \",\n",
        "    backstory = \"\"\"You are a customer research expert who understands how to identify and analyze the right target segment. You excel at finding customer\n",
        "    feedback, reviews , and market surveys to understand customer needs, pain points and usage behavior in the AI chatbot market.\n",
        "    You also understand how mauch your target segment is ready to to pay for AI chatbot.You use web search extensively to gather customer related data\n",
        "    \"\"\",\n",
        "    tools = [search_tool,scrape_tool],\n",
        "    verbose = True,\n",
        "    llm = llm\n",
        ")\n",
        "\n",
        "# New technology Analyst - Analyzes the latest tech trends\n",
        "tech_researcher = Agent(\n",
        "    role = \"Senior Technology Trend Analys\",\n",
        "    goal = \"Analyze emergence of newer technology trends affecting the AI chatbot market \",\n",
        "    backstory = \"\"\"you are a technology analyst specializing in closely tracking technology developments in the AI market.\n",
        "    You always stay up to date with latest developments in LLM, Agentic AI , conversational AI and related technology.\n",
        "    You understand how tech trends can impact market dynamics in mid term and long term features and its impact on market , customers and competitors.\n",
        "    \"\"\",\n",
        "    tools = [search_tool,scrape_tool],\n",
        "    verbose = True,\n",
        "    llm = llm\n",
        ")\n",
        "\n",
        "#### TASK\n",
        "\n",
        "market_analysis_task = Task(\n",
        "    description=\"\"\"\n",
        "    Research and Analyze the AI chatbot market :\n",
        "    1. Current market size and projected growth (2025 - 2035)\n",
        "    2. Key Market Segments ( enterprise, SMB, consumer etc)\n",
        "    3. Geographic distribution of the market and growth pockets\n",
        "    4. Major market drivers and barriers\n",
        "    5. Revenue model and pricing trends\n",
        "\n",
        "    Use web search to find recent market reports , industry analysis , and credible sources. Focus on latest data published between 2023 - 2025.\n",
        "    \"\"\",\n",
        "    agent = market_research_analyst,\n",
        "    async_execution=True,\n",
        "    expected_output = \"Comprehensive market analysis report with specific datapoints, trends and insights - Summary should be in 10 sentences\"\n",
        "\n",
        ")\n",
        "\n",
        "competitive_analysis_task = Task(\n",
        "    description=\"\"\"\n",
        "    Conduct thorough competitive analysis of the AI chatbot market :\n",
        "    1. Idnetify maximum top 10 competitors ( both direct and indirect)\n",
        "    2. Analyze their key features , differences, strengths, weaknesses\n",
        "    3. Research their pricing strategies and busines smodels\n",
        "    4. Assess their market positioning and taregt customers\n",
        "    5. Identify gaps in the market that comeptitors are not addressing\n",
        "\n",
        "    Use web search to find comeptitor data from competitor websites , reviews, industry coverage , media coverage etc.\n",
        "    \"\"\",\n",
        "    agent = competitive_analyst,\n",
        "    async_execution=True,\n",
        "    expected_output = \"Comprehensive research report with competition analysis with competitor profiles, positioning , pricing , market gaps etc. - Summary should be in 10 sentences \"\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "customer_research_task = Task(\n",
        "    description=\"\"\"\n",
        "    research target customers for AI chatbot solution :\n",
        "    1. Identify primary customer segments and their characteristics\n",
        "    2. Analyze customer pain points and unmet needs\n",
        "    3. Research customer preferences and decision making factors for buying or using a chatbot solution\n",
        "    4. Find customer reviews and feedback on existing solution\n",
        "    5. Determine customer acquisition strategies\n",
        "\n",
        "    Use search and scrape to find customer surveys , reviews, case studies and market research.\n",
        "    \"\"\",\n",
        "    agent = customer_researcher,\n",
        "    async_execution=True,\n",
        "    expected_output = \"Comprehensive research report with target customer segment profiles, pain points and insights - Summary should be in 10 sentences\"\n",
        "\n",
        ")\n",
        "\n",
        "tech_trends_task = Task(\n",
        "    description=\"\"\"\n",
        "    Analyze the technology trends impacting AI chatbot market :\n",
        "    1. Latest developments in LLM , Agentic and Conversational AI\n",
        "    2. Emerging technolgies like Voice AI , Image AI , Multimodal AI etc\n",
        "    3. Adoption trends and integration trends\n",
        "    4. Regulatory and ethical consideration\n",
        "    5. Bias handling and responsible AI\n",
        "    6. Future technology roadmaps and implications\n",
        "    Use search and scrape to find customer surveys , reviews, case studies and market research.\n",
        "    \"\"\",\n",
        "    agent = tech_researcher,\n",
        "    async_execution=True,\n",
        "    expected_output = \"Comprehensive technolgy trends analysis with implication for market strategy - Summary should be in 10 sentences\"\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "strategic_insights_synthesizing_task = Task(\n",
        "    description=\"\"\"\n",
        "    Synthesize all research findings into a strategic market entry plan . The plan should include:\n",
        "    1. Summarize key market opportunities and threats\n",
        "    2. Recommend target customer segments and positioning strategy\n",
        "    3. Call out competitive advantage and differentiation to aim for\n",
        "    4. Suggest go to market stategy and timeline\n",
        "    5. Propose picing plan that will work\n",
        "    6. Outline expected revenue and adoption over the next 5 years for this product\n",
        "    7. Next release plans ( vesion 1, vesion 2 etc) - how should it look like\n",
        "    8. Highlight success factos and potential risks\n",
        "\n",
        "    Delegate follow-up reseach to specialists if you need additional insights on specific areas. Use the findings from all pevious research tasks\n",
        "    to create actionable strategic ecommendation\n",
        "    \"\"\",\n",
        "    agent = ceo_agent,\n",
        "    expected_output = \"Strategic market entry plan with clear recommendation and action items - Summary should be in 20 sentences\",\n",
        "    context = [market_analysis_task,competitive_analysis_task,customer_research_task,tech_trends_task]\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tBoqoiZ6nQ4x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e520292-3842-4428-f543-423e4671ce54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the\n",
        "market_research_crew = Crew(\n",
        "    agents =[ceo_agent,market_research_analyst,competitive_analyst,customer_researcher,tech_researcher],\n",
        "    tasks = [market_analysis_task,competitive_analysis_task,customer_research_task,tech_trends_task,strategic_insights_synthesizing_task],\n",
        "    process=Process.hierarchical,\n",
        "    verbose = True,\n",
        "    manager_llm = llm,\n",
        "    mememory = True,\n",
        "    max_iter = 3\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "kV7_P1VrxJD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = market_research_crew.kickoff(\n",
        "    inputs = {'market_focus': \"Making Dashboards Conversational with GenAI\",\n",
        "              'target_region': \"North America and Europe\",\n",
        "              'research_timeframe': \"2023- 2025\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vX7sPPLpzX4p",
        "outputId": "9a3deae7-bada-4880-dbed-99cfe38ed5e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">🚀 Crew: crew</span>\n",
              "├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">📋 Task: 28f49717-0bc2-4365-a05b-22fdba4d8850</span>\n",
              "│   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Assigned to: </span><span style=\"color: #008000; text-decoration-color: #008000\">Crew Manager</span>\n",
              "│   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Status: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Completed</span>\n",
              "│   └── <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">🧠 </span><span style=\"color: #000080; text-decoration-color: #000080\">Thinking...</span>\n",
              "├── <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">📋 Task: a167c719-7f18-44cd-98fc-cf8c0881fc57</span>\n",
              "│   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Assigned to: </span><span style=\"color: #800000; text-decoration-color: #800000\">Crew Manager</span>\n",
              "│   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Status: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">❌ Failed</span>\n",
              "├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">📋 Task: 0b030fc5-a522-4d27-bad6-b4b2dada1516</span>\n",
              "│   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Assigned to: </span><span style=\"color: #008000; text-decoration-color: #008000\">Crew Manager</span>\n",
              "│   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Status: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Completed</span>\n",
              "└── <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">📋 Task: b4f02bf7-af25-4f71-a5c3-6e18809d627f</span>\n",
              "    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Status: </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">Executing Task...</span>\n",
              "    ├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">🔧 </span><span style=\"color: #008000; text-decoration-color: #008000\">Used Search the internet with Serper (2)</span>\n",
              "    ├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">🔧 </span><span style=\"color: #008000; text-decoration-color: #008000\">Used Search the internet with Serper (3)</span>\n",
              "    ├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">🔧 </span><span style=\"color: #008000; text-decoration-color: #008000\">Used Search the internet with Serper (3)</span>\n",
              "    ├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">🔧 </span><span style=\"color: #008000; text-decoration-color: #008000\">Used Delegate work to coworker (1)</span>\n",
              "    ├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">🔧 </span><span style=\"color: #008000; text-decoration-color: #008000\">Used Read website content (3)</span>\n",
              "    ├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">🔧 </span><span style=\"color: #008000; text-decoration-color: #008000\">Used Delegate work to coworker (2)</span>\n",
              "    ├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">🔧 </span><span style=\"color: #008000; text-decoration-color: #008000\">Used Read website content (3)</span>\n",
              "    ├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">🔧 </span><span style=\"color: #008000; text-decoration-color: #008000\">Used Read website content (4)</span>\n",
              "    ├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">🔧 </span><span style=\"color: #008000; text-decoration-color: #008000\">Used Read website content (7)</span>\n",
              "    ├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">🔧 </span><span style=\"color: #008000; text-decoration-color: #008000\">Used Read website content (7)</span>\n",
              "    ├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">🔧 </span><span style=\"color: #008000; text-decoration-color: #008000\">Used Read website content (7)</span>\n",
              "    ├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">🔧 </span><span style=\"color: #008000; text-decoration-color: #008000\">Used Search the internet with Serper (4)</span>\n",
              "    ├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">🔧 </span><span style=\"color: #008000; text-decoration-color: #008000\">Used Read website content (8)</span>\n",
              "    ├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">🔧 </span><span style=\"color: #008000; text-decoration-color: #008000\">Used Read website content (11)</span>\n",
              "    ├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">🔧 </span><span style=\"color: #008000; text-decoration-color: #008000\">Used Read website content (11)</span>\n",
              "    ├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">🔧 </span><span style=\"color: #008000; text-decoration-color: #008000\">Used Read website content (11)</span>\n",
              "    ├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">🔧 </span><span style=\"color: #008000; text-decoration-color: #008000\">Used Read website content (13)</span>\n",
              "    ├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">🔧 </span><span style=\"color: #008000; text-decoration-color: #008000\">Used Read website content (13)</span>\n",
              "    ├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">🔧 </span><span style=\"color: #008000; text-decoration-color: #008000\">Used Read website content (14)</span>\n",
              "    ├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">🔧 </span><span style=\"color: #008000; text-decoration-color: #008000\">Used Read website content (15)</span>\n",
              "    ├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">🔧 </span><span style=\"color: #008000; text-decoration-color: #008000\">Used Search the internet with Serper (5)</span>\n",
              "    ├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">🔧 </span><span style=\"color: #008000; text-decoration-color: #008000\">Used Read website content (16)</span>\n",
              "    ├── <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">🔧 Failed </span><span style=\"color: #800000; text-decoration-color: #800000\">Read website content (19)</span>\n",
              "    ├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">🔧 </span><span style=\"color: #008000; text-decoration-color: #008000\">Used Read website content (20)</span>\n",
              "    └── <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">❌ LLM Failed</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;36m🚀 Crew: \u001b[0m\u001b[1;36mcrew\u001b[0m\n",
              "├── \u001b[1;32m📋 Task: 28f49717-0bc2-4365-a05b-22fdba4d8850\u001b[0m\n",
              "│   \u001b[37mAssigned to: \u001b[0m\u001b[32mCrew Manager\u001b[0m\n",
              "│   \u001b[37mStatus: \u001b[0m\u001b[1;32m✅ Completed\u001b[0m\n",
              "│   └── \u001b[1;34m🧠 \u001b[0m\u001b[34mThinking...\u001b[0m\n",
              "├── \u001b[1;31m📋 Task: a167c719-7f18-44cd-98fc-cf8c0881fc57\u001b[0m\n",
              "│   \u001b[37mAssigned to: \u001b[0m\u001b[31mCrew Manager\u001b[0m\n",
              "│   \u001b[37mStatus: \u001b[0m\u001b[1;31m❌ Failed\u001b[0m\n",
              "├── \u001b[1;32m📋 Task: 0b030fc5-a522-4d27-bad6-b4b2dada1516\u001b[0m\n",
              "│   \u001b[37mAssigned to: \u001b[0m\u001b[32mCrew Manager\u001b[0m\n",
              "│   \u001b[37mStatus: \u001b[0m\u001b[1;32m✅ Completed\u001b[0m\n",
              "└── \u001b[1;33m📋 Task: b4f02bf7-af25-4f71-a5c3-6e18809d627f\u001b[0m\n",
              "    \u001b[37mStatus: \u001b[0m\u001b[2;33mExecuting Task...\u001b[0m\n",
              "    ├── \u001b[1;32m🔧 \u001b[0m\u001b[32mUsed Search the internet with Serper (2)\u001b[0m\n",
              "    ├── \u001b[1;32m🔧 \u001b[0m\u001b[32mUsed Search the internet with Serper (3)\u001b[0m\n",
              "    ├── \u001b[1;32m🔧 \u001b[0m\u001b[32mUsed Search the internet with Serper (3)\u001b[0m\n",
              "    ├── \u001b[1;32m🔧 \u001b[0m\u001b[32mUsed Delegate work to coworker (1)\u001b[0m\n",
              "    ├── \u001b[1;32m🔧 \u001b[0m\u001b[32mUsed Read website content (3)\u001b[0m\n",
              "    ├── \u001b[1;32m🔧 \u001b[0m\u001b[32mUsed Delegate work to coworker (2)\u001b[0m\n",
              "    ├── \u001b[1;32m🔧 \u001b[0m\u001b[32mUsed Read website content (3)\u001b[0m\n",
              "    ├── \u001b[1;32m🔧 \u001b[0m\u001b[32mUsed Read website content (4)\u001b[0m\n",
              "    ├── \u001b[1;32m🔧 \u001b[0m\u001b[32mUsed Read website content (7)\u001b[0m\n",
              "    ├── \u001b[1;32m🔧 \u001b[0m\u001b[32mUsed Read website content (7)\u001b[0m\n",
              "    ├── \u001b[1;32m🔧 \u001b[0m\u001b[32mUsed Read website content (7)\u001b[0m\n",
              "    ├── \u001b[1;32m🔧 \u001b[0m\u001b[32mUsed Search the internet with Serper (4)\u001b[0m\n",
              "    ├── \u001b[1;32m🔧 \u001b[0m\u001b[32mUsed Read website content (8)\u001b[0m\n",
              "    ├── \u001b[1;32m🔧 \u001b[0m\u001b[32mUsed Read website content (11)\u001b[0m\n",
              "    ├── \u001b[1;32m🔧 \u001b[0m\u001b[32mUsed Read website content (11)\u001b[0m\n",
              "    ├── \u001b[1;32m🔧 \u001b[0m\u001b[32mUsed Read website content (11)\u001b[0m\n",
              "    ├── \u001b[1;32m🔧 \u001b[0m\u001b[32mUsed Read website content (13)\u001b[0m\n",
              "    ├── \u001b[1;32m🔧 \u001b[0m\u001b[32mUsed Read website content (13)\u001b[0m\n",
              "    ├── \u001b[1;32m🔧 \u001b[0m\u001b[32mUsed Read website content (14)\u001b[0m\n",
              "    ├── \u001b[1;32m🔧 \u001b[0m\u001b[32mUsed Read website content (15)\u001b[0m\n",
              "    ├── \u001b[1;32m🔧 \u001b[0m\u001b[32mUsed Search the internet with Serper (5)\u001b[0m\n",
              "    ├── \u001b[1;32m🔧 \u001b[0m\u001b[32mUsed Read website content (16)\u001b[0m\n",
              "    ├── \u001b[1;31m🔧 Failed \u001b[0m\u001b[31mRead website content (19)\u001b[0m\n",
              "    ├── \u001b[1;32m🔧 \u001b[0m\u001b[32mUsed Read website content (20)\u001b[0m\n",
              "    └── \u001b[1;31m❌ LLM Failed\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────────────────────────── LLM Error ───────────────────────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>  <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">❌ LLM Call Failed</span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Error: </span><span style=\"color: #800000; text-decoration-color: #800000\">litellm.RateLimitError: RateLimitError: OpenAIException - Request too large for gpt-4o-mini in </span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>  <span style=\"color: #800000; text-decoration-color: #800000\">organization org-VceNXcDo6YKYipYlx8MiGgLN on tokens per min (TPM): Limit 200000, Requested 1854370. The input</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>  <span style=\"color: #800000; text-decoration-color: #800000\">or output tokens must be reduced in order to run successfully. Visit </span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>  <span style=\"color: #800000; text-decoration-color: #800000\">https://platform.openai.com/account/rate-limits to learn more.</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────────────────────────\u001b[0m\u001b[31m LLM Error \u001b[0m\u001b[31m──────────────────────────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m  \u001b[1;31m❌ LLM Call Failed\u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m  \u001b[37mError: \u001b[0m\u001b[31mlitellm.RateLimitError: RateLimitError: OpenAIException - Request too large for gpt-4o-mini in \u001b[0m         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m  \u001b[31morganization org-VceNXcDo6YKYipYlx8MiGgLN on tokens per min (TPM): Limit 200000, Requested 1854370. The input\u001b[0m  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m  \u001b[31mor output tokens must be reduced in order to run successfully. Visit \u001b[0m                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m  \u001b[31mhttps://platform.openai.com/account/rate-limits to learn more.\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭───────────────────────────────────────────────── Task Failure ──────────────────────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>  <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Task Failed</span>                                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #800000; text-decoration-color: #800000\">b4f02bf7-af25-4f71-a5c3-6e18809d627f</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #800000; text-decoration-color: #800000\">Crew Manager</span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Tool Args: </span>                                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────────────────────────────────\u001b[0m\u001b[31m Task Failure \u001b[0m\u001b[31m─────────────────────────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m  \u001b[1;31mTask Failed\u001b[0m                                                                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m  \u001b[37mName: \u001b[0m\u001b[31mb4f02bf7-af25-4f71-a5c3-6e18809d627f\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[31mCrew Manager\u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m  \u001b[37mTool Args: \u001b[0m                                                                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-9 (_execute_task_async):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/litellm/llms/openai/openai.py\", line 725, in completion\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/litellm/llms/openai/openai.py\", line 653, in completion\n",
            "    ) = self.make_sync_openai_chat_completion_request(\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/litellm/litellm_core_utils/logging_utils.py\", line 149, in sync_wrapper\n",
            "    result = func(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/litellm/llms/openai/openai.py\", line 453, in make_sync_openai_chat_completion_request\n",
            "    raw_response = openai_client.chat.completions.with_raw_response.create(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/_legacy_response.py\", line 364, in wrapped\n",
            "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
            "                                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\", line 287, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 1150, in create\n",
            "    return self._post(\n",
            "           ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1259, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1047, in request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o-mini in organization org-VceNXcDo6YKYipYlx8MiGgLN on tokens per min (TPM): Limit 200000, Requested 1854370. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/litellm/main.py\", line 1966, in completion\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/litellm/main.py\", line 1939, in completion\n",
            "    response = openai_chat_completions.completion(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/litellm/llms/openai/openai.py\", line 736, in completion\n",
            "    raise OpenAIError(\n",
            "litellm.llms.openai.common_utils.OpenAIError: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o-mini in organization org-VceNXcDo6YKYipYlx8MiGgLN on tokens per min (TPM): Limit 200000, Requested 1854370. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/crewai/task.py\", line 420, in _execute_task_async\n",
            "    result = self._execute_core(agent, context, tools)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/crewai/task.py\", line 529, in _execute_core\n",
            "    raise e  # Re-raise the exception after emitting the event\n",
            "    ^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/crewai/task.py\", line 445, in _execute_core\n",
            "    result = agent.execute_task(\n",
            "             ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/crewai/agent.py\", line 475, in execute_task\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/crewai/agent.py\", line 451, in execute_task\n",
            "    result = self._execute_without_timeout(task_prompt, task)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/crewai/agent.py\", line 547, in _execute_without_timeout\n",
            "    return self.agent_executor.invoke(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/crewai/agents/crew_agent_executor.py\", line 149, in invoke\n",
            "    formatted_answer = self._invoke_loop()\n",
            "                       ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/crewai/agents/crew_agent_executor.py\", line 243, in _invoke_loop\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/crewai/agents/crew_agent_executor.py\", line 189, in _invoke_loop\n",
            "    answer = get_llm_response(\n",
            "             ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/crewai/utilities/agent_utils.py\", line 161, in get_llm_response\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/crewai/utilities/agent_utils.py\", line 154, in get_llm_response\n",
            "    answer = llm.call(\n",
            "             ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/crewai/llm.py\", line 1032, in call\n",
            "    return self._handle_non_streaming_response(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/crewai/llm.py\", line 813, in _handle_non_streaming_response\n",
            "    response = litellm.completion(**params)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/litellm/utils.py\", line 1330, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/litellm/utils.py\", line 1205, in wrapper\n",
            "    result = original_function(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/litellm/main.py\", line 3427, in completion\n",
            "    raise exception_type(\n",
            "          ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2301, in exception_type\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 329, in exception_type\n",
            "    raise RateLimitError(\n",
            "litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenAIException - Request too large for gpt-4o-mini in organization org-VceNXcDo6YKYipYlx8MiGgLN on tokens per min (TPM): Limit 200000, Requested 1854370. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown, HTML\n",
        "Markdown(results.raw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "oVf54C2Az8LE",
        "outputId": "10175d7c-7ecd-4e7d-ad19-c430b5095ac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Strategic Market Entry Plan for AI Chatbot Sector**\n\n1. **Market Overview**: The global AI chatbot market is projected to grow from USD 5.84 billion in 2025 to USD 61.97 billion by 2035, with a compound annual growth rate (CAGR) of approximately 23.94%. This growth is driven by advancements in artificial intelligence and natural language processing, alongside increasing demand for 24/7 customer support.\n\n2. **Key Market Opportunities**: The primary opportunities lie in targeting small to medium enterprises (SMEs), e-commerce platforms, and healthcare providers. Each segment presents unique needs that our chatbot can address, such as cost-effective solutions for SMEs and patient engagement for healthcare providers.\n\n3. **Market Threats**: Challenges include data privacy concerns and the need for effective integration with existing systems. Competitors like ChatGPT, Microsoft Copilot, and Google Gemini dominate the market, emphasizing the need for differentiation.\n\n4. **Target Customer Segments**: We will focus on SMEs seeking scalable solutions, e-commerce businesses needing enhanced customer service, and healthcare providers looking for patient engagement tools. Each segment will require tailored marketing strategies to address their specific pain points.\n\n5. **Positioning Strategy**: Our chatbot will be positioned as a highly customizable and secure solution that integrates seamlessly with existing systems. We will emphasize our advanced natural language processing capabilities to provide human-like interactions.\n\n6. **Competitive Advantage**: Our key differentiators will include superior NLP capabilities, robust customization options, and a strong commitment to data security and compliance. These factors will help us stand out in a crowded market.\n\n7. **Go-to-Market Strategy**: We will implement a multi-channel marketing approach, leveraging content marketing, webinars, and partnerships with technology providers to establish our brand as an authority in the AI chatbot space. Targeted advertising campaigns will focus on our key customer segments.\n\n8. **Timeline**: The go-to-market strategy will unfold over the next 12 months, with initial product launches aimed at SMEs and e-commerce platforms, followed by targeted outreach to healthcare providers.\n\n9. **Pricing Plan**: We will adopt a subscription-based pricing model with tiered options to cater to different customer needs. This approach will allow us to capture a broad customer base while providing flexibility for scaling.\n\n10. **Expected Revenue and Adoption**: We anticipate steady revenue growth, projecting a 20% increase in customer acquisition each year for the next five years, leading to significant market penetration and brand recognition.\n\n11. **Next Release Plans**: Future versions of our chatbot will focus on enhancing multilingual support and emotional intelligence capabilities, addressing gaps identified in customer feedback and market research.\n\n12. **Success Factors**: Key success factors will include continuous product innovation, effective customer support, and strong marketing efforts. Building a community around our product will also foster customer loyalty.\n\n13. **Potential Risks**: Risks include evolving regulatory landscapes regarding data privacy and potential technological challenges in integration. We will proactively address these risks through compliance measures and ongoing technical support.\n\n14. **Conclusion**: The AI chatbot market presents a robust opportunity for growth. By focusing on targeted customer segments, leveraging our competitive advantages, and implementing a comprehensive go-to-market strategy, we can successfully enter and thrive in this dynamic market.\n\nThis strategic market entry plan outlines actionable recommendations and clear action items to ensure successful implementation and long-term growth in the AI chatbot sector."
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Goal : Break any business problem into roles\n",
        "# - Specialized Roles ( as much as specialized the role is better the result is)\n",
        "# - Key about defining roles - every role should have a clear goal and he should be having access to specific tools or knowledge required to answer that goal\n",
        "# - Costlier and Latency impact"
      ],
      "metadata": {
        "id": "1BETLKI010Y6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}