{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18dd39dd",
   "metadata": {},
   "source": [
    "## What is Semantic Caching?\n",
    "- Semantic caching stores query results based on semantic similarity rather than exact string matches. Unlike traditional caching that requires identical queries, semantic caching can serve cached responses for queries with similar meaning.\n",
    "### When is Semantic Caching Used?\n",
    "\n",
    "- High-frequency similar queries - Customer support, FAQ systems\n",
    "- Expensive retrieval operations - Large vector database searches\n",
    "- LLM API cost optimization - Reducing expensive API calls\n",
    "- Real-time applications - Chatbots, search engines requiring fast responses\n",
    "\n",
    "### How It Works:\n",
    "\n",
    "- Query Processing: Convert queries to embeddings using models like OpenAI's text-embedding-ada-002\n",
    "- Similarity Check: Calculate cosine similarity between new query and cached queries\n",
    "- Threshold Decision: If similarity > threshold (typically 0.85-0.9), return cached result\n",
    "- Cache Storage: Store new query-response pairs with their embeddings\n",
    "\n",
    "### Key Differences (With vs Without Semantic Caching):\n",
    "- Without Semantic Caching:\n",
    "\n",
    "Response time: 1200-2000ms\n",
    "Every query hits the vector database and LLM\n",
    "Cost: $0.02-0.05 per query\n",
    "No reuse of similar queries\n",
    "\n",
    "- With Semantic Caching:\n",
    "\n",
    "Response time: 100-300ms (80-90% faster)\n",
    "Vector DB queries only for cache misses\n",
    "Cost: $0.001-0.01 per query (60-80% reduction)\n",
    "Intelligent reuse based on meaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a068cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import React, { useState, useEffect } from 'react';\n",
    "import { Search, Clock, Database, Zap, BarChart3, RefreshCw } from 'lucide-react';\n",
    "\n",
    "const SemanticCachingDemo = () => {\n",
    "  const [query, setQuery] = useState('');\n",
    "  const [results, setResults] = useState(null);\n",
    "  const [isLoading, setIsLoading] = useState(false);\n",
    "  const [cacheEnabled, setCacheEnabled] = useState(true);\n",
    "  const [stats, setStats] = useState({\n",
    "    cacheHits: 0,\n",
    "    cacheMisses: 0,\n",
    "    totalQueries: 0,\n",
    "    avgResponseTime: 0\n",
    "  });\n",
    "\n",
    "  // Demo knowledge base\n",
    "  const knowledgeBase = [\n",
    "    { id: 1, content: \"Machine learning is a subset of artificial intelligence that enables computers to learn and make decisions from data without being explicitly programmed.\", topic: \"ML Basics\" },\n",
    "    { id: 2, content: \"Deep learning uses neural networks with multiple layers to model and understand complex patterns in data, similar to how the human brain processes information.\", topic: \"Deep Learning\" },\n",
    "    { id: 3, content: \"Natural language processing (NLP) is a branch of AI that helps computers understand, interpret, and generate human language in a meaningful way.\", topic: \"NLP\" },\n",
    "    { id: 4, content: \"Computer vision enables machines to identify and analyze visual content from images and videos, including object detection and image classification.\", topic: \"Computer Vision\" },\n",
    "    { id: 5, content: \"Reinforcement learning is a type of machine learning where agents learn to make decisions by receiving rewards or penalties for their actions in an environment.\", topic: \"Reinforcement Learning\" }\n",
    "  ];\n",
    "\n",
    "  // Semantic cache with similarity scores\n",
    "  const [semanticCache, setSemanticCache] = useState([\n",
    "    { query: \"what is machine learning\", embedding: [0.8, 0.6, 0.9, 0.2, 0.3], response: \"Machine learning is a subset of AI that learns from data\", timestamp: Date.now() - 60000 },\n",
    "    { query: \"explain deep learning\", embedding: [0.7, 0.9, 0.8, 0.1, 0.4], response: \"Deep learning uses multi-layer neural networks\", timestamp: Date.now() - 120000 },\n",
    "    { query: \"how does NLP work\", embedding: [0.6, 0.3, 0.7, 0.9, 0.2], response: \"NLP processes and understands human language\", timestamp: Date.now() - 180000 }\n",
    "  ]);\n",
    "\n",
    "  // Simple embedding simulation (in real systems, this would use models like BERT, OpenAI embeddings, etc.)\n",
    "  const generateEmbedding = (text) => {\n",
    "    const words = text.toLowerCase().split(' ');\n",
    "    const embedding = [0, 0, 0, 0, 0];\n",
    "    \n",
    "    // Simple keyword-based embedding simulation\n",
    "    if (words.some(w => ['machine', 'learning', 'ml'].includes(w))) embedding[0] += 0.8;\n",
    "    if (words.some(w => ['deep', 'neural', 'network'].includes(w))) embedding[1] += 0.9;\n",
    "    if (words.some(w => ['language', 'nlp', 'text'].includes(w))) embedding[2] += 0.7;\n",
    "    if (words.some(w => ['vision', 'image', 'visual'].includes(w))) embedding[3] += 0.8;\n",
    "    if (words.some(w => ['reinforcement', 'reward', 'agent'].includes(w))) embedding[4] += 0.9;\n",
    "    \n",
    "    return embedding.map(val => Math.min(val + Math.random() * 0.3, 1));\n",
    "  };\n",
    "\n",
    "  // Calculate cosine similarity\n",
    "  const cosineSimilarity = (vec1, vec2) => {\n",
    "    const dotProduct = vec1.reduce((sum, a, i) => sum + a * vec2[i], 0);\n",
    "    const magnitude1 = Math.sqrt(vec1.reduce((sum, a) => sum + a * a, 0));\n",
    "    const magnitude2 = Math.sqrt(vec2.reduce((sum, a) => sum + a * a, 0));\n",
    "    return dotProduct / (magnitude1 * magnitude2);\n",
    "  };\n",
    "\n",
    "  // RAG retrieval simulation\n",
    "  const retrieveRelevantDocs = (queryEmbedding) => {\n",
    "    // Simulate document retrieval based on similarity\n",
    "    const docScores = knowledgeBase.map(doc => ({\n",
    "      ...doc,\n",
    "      score: Math.random() * 0.5 + 0.5 // Simulate relevance scoring\n",
    "    }));\n",
    "    return docScores.sort((a, b) => b.score - a.score).slice(0, 2);\n",
    "  };\n",
    "\n",
    "  // Generate response from retrieved documents\n",
    "  const generateResponse = (docs, query) => {\n",
    "    const context = docs.map(doc => doc.content).join(' ');\n",
    "    return `Based on the retrieved information: ${docs[0].content.substring(0, 100)}...`;\n",
    "  };\n",
    "\n",
    "  // Search with semantic caching\n",
    "  const handleSearch = async () => {\n",
    "    if (!query.trim()) return;\n",
    "    \n",
    "    setIsLoading(true);\n",
    "    const startTime = Date.now();\n",
    "    const queryEmbedding = generateEmbedding(query);\n",
    "    \n",
    "    let response;\n",
    "    let fromCache = false;\n",
    "    \n",
    "    if (cacheEnabled) {\n",
    "      // Check semantic cache\n",
    "      const threshold = 0.85; // Similarity threshold\n",
    "      const cacheHit = semanticCache.find(cached => \n",
    "        cosineSimilarity(cached.embedding, queryEmbedding) > threshold\n",
    "      );\n",
    "      \n",
    "      if (cacheHit) {\n",
    "        response = `[CACHED] ${cacheHit.response}`;\n",
    "        fromCache = true;\n",
    "        setStats(prev => ({ ...prev, cacheHits: prev.cacheHits + 1 }));\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    if (!fromCache) {\n",
    "      // Perform RAG retrieval and generation\n",
    "      await new Promise(resolve => setTimeout(resolve, 1500)); // Simulate processing time\n",
    "      const relevantDocs = retrieveRelevantDocs(queryEmbedding);\n",
    "      response = generateResponse(relevantDocs, query);\n",
    "      \n",
    "      // Add to semantic cache\n",
    "      if (cacheEnabled) {\n",
    "        setSemanticCache(prev => [...prev, {\n",
    "          query,\n",
    "          embedding: queryEmbedding,\n",
    "          response,\n",
    "          timestamp: Date.now()\n",
    "        }]);\n",
    "      }\n",
    "      \n",
    "      setStats(prev => ({ ...prev, cacheMisses: prev.cacheMisses + 1 }));\n",
    "    }\n",
    "    \n",
    "    const endTime = Date.now();\n",
    "    const responseTime = endTime - startTime;\n",
    "    \n",
    "    setResults({\n",
    "      query,\n",
    "      response,\n",
    "      fromCache,\n",
    "      responseTime,\n",
    "      retrievedDocs: fromCache ? [] : retrieveRelevantDocs(queryEmbedding)\n",
    "    });\n",
    "    \n",
    "    setStats(prev => ({\n",
    "      ...prev,\n",
    "      totalQueries: prev.totalQueries + 1,\n",
    "      avgResponseTime: Math.round((prev.avgResponseTime * (prev.totalQueries - 1) + responseTime) / prev.totalQueries)\n",
    "    }));\n",
    "    \n",
    "    setIsLoading(false);\n",
    "  };\n",
    "\n",
    "  const clearCache = () => {\n",
    "    setSemanticCache([]);\n",
    "    setStats({ cacheHits: 0, cacheMisses: 0, totalQueries: 0, avgResponseTime: 0 });\n",
    "  };\n",
    "\n",
    "  const sampleQueries = [\n",
    "    \"what is machine learning?\",\n",
    "    \"explain artificial intelligence\",\n",
    "    \"how does deep learning work?\",\n",
    "    \"what are neural networks?\",\n",
    "    \"tell me about NLP\",\n",
    "    \"computer vision applications\"\n",
    "  ];\n",
    "\n",
    "  return (\n",
    "    <div className=\"max-w-6xl mx-auto p-6 bg-gradient-to-br from-blue-50 to-indigo-100 min-h-screen\">\n",
    "      <div className=\"mb-8 text-center\">\n",
    "        <h1 className=\"text-4xl font-bold text-gray-800 mb-4\">Semantic Caching in RAG Applications</h1>\n",
    "        <p className=\"text-lg text-gray-600 max-w-4xl mx-auto\">\n",
    "          Semantic caching stores query results based on semantic similarity rather than exact matches, \n",
    "          reducing response times and computational costs in RAG systems.\n",
    "        </p>\n",
    "      </div>\n",
    "\n",
    "      {/* Theory Section */}\n",
    "      <div className=\"bg-white rounded-lg shadow-lg p-6 mb-6\">\n",
    "        <h2 className=\"text-2xl font-bold text-gray-800 mb-4 flex items-center\">\n",
    "          <Database className=\"mr-2 text-blue-600\" />\n",
    "          What is Semantic Caching?\n",
    "        </h2>\n",
    "        <div className=\"grid md:grid-cols-2 gap-6\">\n",
    "          <div>\n",
    "            <h3 className=\"text-lg font-semibold text-gray-700 mb-2\">Traditional Caching vs Semantic Caching</h3>\n",
    "            <div className=\"space-y-3\">\n",
    "              <div className=\"p-3 bg-red-50 rounded border-l-4 border-red-400\">\n",
    "                <strong>Traditional:</strong> Exact string match only<br/>\n",
    "                <span className=\"text-sm text-gray-600\">\"what is ML?\" ≠ \"explain machine learning\"</span>\n",
    "              </div>\n",
    "              <div className=\"p-3 bg-green-50 rounded border-l-4 border-green-400\">\n",
    "                <strong>Semantic:</strong> Meaning-based similarity<br/>\n",
    "                <span className=\"text-sm text-gray-600\">\"what is ML?\" ≈ \"explain machine learning\" (85% similar)</span>\n",
    "              </div>\n",
    "            </div>\n",
    "          </div>\n",
    "          <div>\n",
    "            <h3 className=\"text-lg font-semibold text-gray-700 mb-2\">When is it Used?</h3>\n",
    "            <ul className=\"space-y-2 text-sm text-gray-600\">\n",
    "              <li>• <strong>High-frequency similar queries:</strong> Customer support, FAQ systems</li>\n",
    "              <li>• <strong>Expensive retrieval operations:</strong> Large vector databases</li>\n",
    "              <li>• <strong>LLM API cost optimization:</strong> Reducing API calls</li>\n",
    "              <li>• <strong>Real-time applications:</strong> Chatbots, search engines</li>\n",
    "            </ul>\n",
    "          </div>\n",
    "        </div>\n",
    "      </div>\n",
    "\n",
    "      {/* Demo Interface */}\n",
    "      <div className=\"grid lg:grid-cols-2 gap-6 mb-6\">\n",
    "        {/* Search Interface */}\n",
    "        <div className=\"bg-white rounded-lg shadow-lg p-6\">\n",
    "          <h3 className=\"text-xl font-bold text-gray-800 mb-4 flex items-center\">\n",
    "            <Search className=\"mr-2 text-blue-600\" />\n",
    "            RAG Query Interface\n",
    "          </h3>\n",
    "          \n",
    "          <div className=\"mb-4\">\n",
    "            <label className=\"flex items-center space-x-2 text-sm font-medium text-gray-700 mb-2\">\n",
    "              <input\n",
    "                type=\"checkbox\"\n",
    "                checked={cacheEnabled}\n",
    "                onChange={(e) => setCacheEnabled(e.target.checked)}\n",
    "                className=\"rounded\"\n",
    "              />\n",
    "              <span>Enable Semantic Caching</span>\n",
    "            </label>\n",
    "          </div>\n",
    "\n",
    "          <div className=\"mb-4\">\n",
    "            <input\n",
    "              type=\"text\"\n",
    "              value={query}\n",
    "              onChange={(e) => setQuery(e.target.value)}\n",
    "              placeholder=\"Enter your query...\"\n",
    "              className=\"w-full p-3 border rounded-lg focus:ring-2 focus:ring-blue-500 focus:border-transparent\"\n",
    "              onKeyPress={(e) => e.key === 'Enter' && handleSearch()}\n",
    "            />\n",
    "            <button\n",
    "              onClick={handleSearch}\n",
    "              disabled={isLoading || !query.trim()}\n",
    "              className=\"mt-2 w-full bg-blue-600 text-white py-2 px-4 rounded-lg hover:bg-blue-700 disabled:opacity-50 disabled:cursor-not-allowed flex items-center justify-center\"\n",
    "            >\n",
    "              {isLoading ? <RefreshCw className=\"animate-spin mr-2\" size={16} /> : <Search className=\"mr-2\" size={16} />}\n",
    "              {isLoading ? 'Processing...' : 'Search'}\n",
    "            </button>\n",
    "          </div>\n",
    "\n",
    "          <div className=\"mb-4\">\n",
    "            <h4 className=\"text-sm font-medium text-gray-700 mb-2\">Sample Queries:</h4>\n",
    "            <div className=\"flex flex-wrap gap-2\">\n",
    "              {sampleQueries.map((sample, idx) => (\n",
    "                <button\n",
    "                  key={idx}\n",
    "                  onClick={() => setQuery(sample)}\n",
    "                  className=\"text-xs bg-gray-100 hover:bg-gray-200 px-2 py-1 rounded transition-colors\"\n",
    "                >\n",
    "                  {sample}\n",
    "                </button>\n",
    "              ))}\n",
    "            </div>\n",
    "          </div>\n",
    "\n",
    "          {results && (\n",
    "            <div className=\"mt-4 p-4 bg-gray-50 rounded-lg\">\n",
    "              <div className=\"flex items-center justify-between mb-2\">\n",
    "                <h4 className=\"font-medium text-gray-800\">Response</h4>\n",
    "                <div className=\"flex items-center space-x-4 text-sm text-gray-600\">\n",
    "                  <span className={`flex items-center ${results.fromCache ? 'text-green-600' : 'text-orange-600'}`}>\n",
    "                    {results.fromCache ? <Zap size={14} className=\"mr-1\" /> : <Clock size={14} className=\"mr-1\" />}\n",
    "                    {results.fromCache ? 'Cached' : 'Generated'}\n",
    "                  </span>\n",
    "                  <span>{results.responseTime}ms</span>\n",
    "                </div>\n",
    "              </div>\n",
    "              <p className=\"text-sm text-gray-700 bg-white p-3 rounded border\">\n",
    "                {results.response}\n",
    "              </p>\n",
    "              {!results.fromCache && results.retrievedDocs && (\n",
    "                <div className=\"mt-2\">\n",
    "                  <h5 className=\"text-xs font-medium text-gray-600 mb-1\">Retrieved Documents:</h5>\n",
    "                  <div className=\"space-y-1\">\n",
    "                    {results.retrievedDocs.map((doc, idx) => (\n",
    "                      <div key={idx} className=\"text-xs bg-blue-50 p-2 rounded\">\n",
    "                        <strong>{doc.topic}</strong> (Score: {doc.score.toFixed(2)})\n",
    "                      </div>\n",
    "                    ))}\n",
    "                  </div>\n",
    "                </div>\n",
    "              )}\n",
    "            </div>\n",
    "          )}\n",
    "        </div>\n",
    "\n",
    "        {/* Cache Status */}\n",
    "        <div className=\"bg-white rounded-lg shadow-lg p-6\">\n",
    "          <h3 className=\"text-xl font-bold text-gray-800 mb-4 flex items-center justify-between\">\n",
    "            <span className=\"flex items-center\">\n",
    "              <Database className=\"mr-2 text-green-600\" />\n",
    "              Semantic Cache Status\n",
    "            </span>\n",
    "            <button\n",
    "              onClick={clearCache}\n",
    "              className=\"text-sm bg-red-100 text-red-700 px-3 py-1 rounded hover:bg-red-200\"\n",
    "            >\n",
    "              Clear Cache\n",
    "            </button>\n",
    "          </h3>\n",
    "\n",
    "          <div className=\"mb-4\">\n",
    "            <h4 className=\"font-medium text-gray-700 mb-2\">Cached Queries ({semanticCache.length})</h4>\n",
    "            <div className=\"space-y-2 max-h-40 overflow-y-auto\">\n",
    "              {semanticCache.map((cached, idx) => (\n",
    "                <div key={idx} className=\"text-sm bg-gray-50 p-2 rounded\">\n",
    "                  <div className=\"font-medium text-gray-700 truncate\">{cached.query}</div>\n",
    "                  <div className=\"text-xs text-gray-500\">\n",
    "                    Cached {Math.round((Date.now() - cached.timestamp) / 1000)}s ago\n",
    "                  </div>\n",
    "                </div>\n",
    "              ))}\n",
    "            </div>\n",
    "          </div>\n",
    "\n",
    "          <div className=\"grid grid-cols-2 gap-4\">\n",
    "            <div className=\"bg-green-50 p-3 rounded text-center\">\n",
    "              <div className=\"text-2xl font-bold text-green-700\">{stats.cacheHits}</div>\n",
    "              <div className=\"text-sm text-green-600\">Cache Hits</div>\n",
    "            </div>\n",
    "            <div className=\"bg-orange-50 p-3 rounded text-center\">\n",
    "              <div className=\"text-2xl font-bold text-orange-700\">{stats.cacheMisses}</div>\n",
    "              <div className=\"text-sm text-orange-600\">Cache Misses</div>\n",
    "            </div>\n",
    "          </div>\n",
    "\n",
    "          <div className=\"mt-4 text-center\">\n",
    "            <div className=\"text-lg font-bold text-gray-700\">{stats.avgResponseTime}ms</div>\n",
    "            <div className=\"text-sm text-gray-600\">Avg Response Time</div>\n",
    "          </div>\n",
    "\n",
    "          {stats.totalQueries > 0 && (\n",
    "            <div className=\"mt-4 bg-blue-50 p-3 rounded\">\n",
    "              <div className=\"text-sm text-blue-700\">\n",
    "                <strong>Cache Hit Rate:</strong> {Math.round((stats.cacheHits / stats.totalQueries) * 100)}%\n",
    "              </div>\n",
    "            </div>\n",
    "          )}\n",
    "        </div>\n",
    "      </div>\n",
    "\n",
    "      {/* Performance Comparison */}\n",
    "      <div className=\"bg-white rounded-lg shadow-lg p-6\">\n",
    "        <h3 className=\"text-xl font-bold text-gray-800 mb-4 flex items-center\">\n",
    "          <BarChart3 className=\"mr-2 text-purple-600\" />\n",
    "          Performance Impact Analysis\n",
    "        </h3>\n",
    "        <div className=\"grid md:grid-cols-2 gap-6\">\n",
    "          <div>\n",
    "            <h4 className=\"font-semibold text-gray-700 mb-3\">Without Semantic Caching</h4>\n",
    "            <div className=\"space-y-2 text-sm\">\n",
    "              <div className=\"flex justify-between\">\n",
    "                <span>Average Response Time:</span>\n",
    "                <span className=\"font-medium text-red-600\">1200-2000ms</span>\n",
    "              </div>\n",
    "              <div className=\"flex justify-between\">\n",
    "                <span>Vector DB Queries:</span>\n",
    "                <span className=\"font-medium text-red-600\">Every request</span>\n",
    "              </div>\n",
    "              <div className=\"flex justify-between\">\n",
    "                <span>LLM API Calls:</span>\n",
    "                <span className=\"font-medium text-red-600\">Every request</span>\n",
    "              </div>\n",
    "              <div className=\"flex justify-between\">\n",
    "                <span>Cost per Query:</span>\n",
    "                <span className=\"font-medium text-red-600\">$0.02-0.05</span>\n",
    "              </div>\n",
    "            </div>\n",
    "          </div>\n",
    "          <div>\n",
    "            <h4 className=\"font-semibold text-gray-700 mb-3\">With Semantic Caching</h4>\n",
    "            <div className=\"space-y-2 text-sm\">\n",
    "              <div className=\"flex justify-between\">\n",
    "                <span>Average Response Time:</span>\n",
    "                <span className=\"font-medium text-green-600\">100-300ms</span>\n",
    "              </div>\n",
    "              <div className=\"flex justify-between\">\n",
    "                <span>Vector DB Queries:</span>\n",
    "                <span className=\"font-medium text-green-600\">Cache misses only</span>\n",
    "              </div>\n",
    "              <div className=\"flex justify-between\">\n",
    "                <span>LLM API Calls:</span>\n",
    "                <span className=\"font-medium text-green-600\">Cache misses only</span>\n",
    "              </div>\n",
    "              <div className=\"flex justify-between\">\n",
    "                <span>Cost per Query:</span>\n",
    "                <span className=\"font-medium text-green-600\">$0.001-0.01</span>\n",
    "              </div>\n",
    "            </div>\n",
    "          </div>\n",
    "        </div>\n",
    "        <div className=\"mt-4 p-4 bg-yellow-50 rounded-lg\">\n",
    "          <h5 className=\"font-semibold text-yellow-800 mb-2\">Key Benefits:</h5>\n",
    "          <ul className=\"text-sm text-yellow-700 space-y-1\">\n",
    "            <li>• <strong>80-90% faster response times</strong> for similar queries</li>\n",
    "            <li>• <strong>60-80% cost reduction</strong> in API usage</li>\n",
    "            <li>• <strong>Reduced server load</strong> and better scalability</li>\n",
    "            <li>• <strong>Improved user experience</strong> with instant responses</li>\n",
    "          </ul>\n",
    "        </div>\n",
    "      </div>\n",
    "\n",
    "      {/* Implementation Notes */}\n",
    "      <div className=\"mt-6 bg-white rounded-lg shadow-lg p-6\">\n",
    "        <h3 className=\"text-xl font-bold text-gray-800 mb-4\">Implementation Considerations</h3>\n",
    "        <div className=\"grid md:grid-cols-3 gap-4 text-sm\">\n",
    "          <div className=\"bg-blue-50 p-4 rounded\">\n",
    "            <h4 className=\"font-semibold text-blue-800 mb-2\">Embedding Models</h4>\n",
    "            <ul className=\"text-blue-700 space-y-1\">\n",
    "              <li>• OpenAI text-embedding-ada-002</li>\n",
    "              <li>• Sentence-BERT models</li>\n",
    "              <li>• Cohere embeddings</li>\n",
    "              <li>• Custom domain-specific models</li>\n",
    "            </ul>\n",
    "          </div>\n",
    "          <div className=\"bg-green-50 p-4 rounded\">\n",
    "            <h4 className=\"font-semibold text-green-800 mb-2\">Storage Options</h4>\n",
    "            <ul className=\"text-green-700 space-y-1\">\n",
    "              <li>• Redis with vector similarity</li>\n",
    "              <li>• Elasticsearch with dense vectors</li>\n",
    "              <li>• Pinecone with metadata filtering</li>\n",
    "              <li>• In-memory caches (LRU)</li>\n",
    "            </ul>\n",
    "          </div>\n",
    "          <div className=\"bg-purple-50 p-4 rounded\">\n",
    "            <h4 className=\"font-semibold text-purple-800 mb-2\">Best Practices</h4>\n",
    "            <ul className=\"text-purple-700 space-y-1\">\n",
    "              <li>• Similarity threshold: 0.8-0.9</li>\n",
    "              <li>• Cache TTL: 1-24 hours</li>\n",
    "              <li>• Monitor hit rates regularly</li>\n",
    "              <li>• Handle cache invalidation</li>\n",
    "            </ul>\n",
    "          </div>\n",
    "        </div>\n",
    "      </div>\n",
    "    </div>\n",
    "  );\n",
    "};\n",
    "\n",
    "export default SemanticCachingDemo;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00a83e6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0d0cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Caching \n",
    "# Save exact query -> response pair ( memcache)\n",
    "\n",
    "# Semantic caching\n",
    "# Similar Queries --> a result \n",
    "\n",
    "# Instead of matching only exact queries , we store the embedding of the query\n",
    "# when a new query comes in we check if it is similar one to a pre existing cached query \n",
    "# if yes , then return the cached answer - this way you save lot of money by skipping expensive LLM calls or Database lookups \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63026bf3",
   "metadata": {},
   "source": [
    "# Technical Implementation Details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96c8bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Setting it up \n",
    "# initialized vector store for semantic cache\n",
    "# decie which Embedding and LLM to use\n",
    "embeddings = OpenAIEmbeddings(model = \"text-embedding-3-small\")\n",
    "\n",
    "from langchain.chroma import Chroma\n",
    "cache_vector_store = Chroma(collection_name = \"semantic_cache\", embeddings =embeddings )\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model = \"gpt-4o-mini\")\n",
    "\n",
    "# Step2: Define cache check \n",
    "similarity_threshold = 0.9 \n",
    "\n",
    "def check_cache(query:str):\n",
    "    \"\"\"Check if sematically similar query exists in cache\"\"\"\n",
    "    results = cache_vector_store.similarity_search(query , k = 1)\n",
    "    if results and results[0].metadata.get(\"similarity\",0)>similarity_threshold:\n",
    "        return results[0].page_content\n",
    "    return None\n",
    "\n",
    "def update_cache(query:str , response :str):\n",
    "    \"\"\"Store query + response in cache for future\"\"\"\n",
    "    # use query as a unique id for uniqueness\n",
    "    query_hash = hashlib.md5(query.encode())# ????\n",
    "    doc = Document(page_content = response, metadata = {\"query\":query })\n",
    "    cache_vector_store.add_documents([doc],ids =[query_hash] )\n",
    "\n",
    "# Step 3: RAG Workflow with cache\n",
    "# 3a: - Chech semantic cache\n",
    "cached_response = check_cache(query)\n",
    "if cached_response:\n",
    "    return cached_response\n",
    "\n",
    "# if cachec os not there then go ahead with rest of RAG workflow\n",
    "# Update cache\n",
    "update_cache(query, response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6422fefe",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
