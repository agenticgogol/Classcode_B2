{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c9abc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utsabchakraborty/Documents/Agentic_Class_Live/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7860\n",
      "* Running on public URL: https://12faf331e5ae567f12.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://12faf331e5ae567f12.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting system initialization...\n",
      "Initializing embeddings...\n",
      "Embeddings initialized successfully\n",
      "Initializing ChromaDB...\n",
      "ChromaDB initialized successfully\n",
      "Collections created successfully\n",
      "System initialization completed!\n"
     ]
    }
   ],
   "source": [
    "# Phase 1: Basic Multimodal RAG System with Gemini\n",
    "# Requirements: pip install gradio chromadb langchain sentence-transformers google-generativeai pypdf pillow python-docx python-pptx\n",
    "\n",
    "import gradio as gr\n",
    "import google.generativeai as genai\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# Fixed import for HuggingFace embeddings\n",
    "try:\n",
    "    from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "except ImportError:\n",
    "    from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import openai\n",
    "\n",
    "\n",
    "# Document processing imports\n",
    "import PyPDF2\n",
    "from docx import Document\n",
    "from pptx import Presentation\n",
    "\n",
    "# Initialize ChromaDB for vector storage\n",
    "class MultimodalRAG:\n",
    "    def __init__(self, gemini_api_key: str, openai_api_key: str):\n",
    "        \"\"\"\n",
    "        Initialize the Multimodal RAG system\n",
    "        \n",
    "        Args:\n",
    "            gemini_api_key: Your Gemini API key\n",
    "        \"\"\"\n",
    "        # Configure Gemini\n",
    "        genai.configure(api_key=gemini_api_key)\n",
    "        self.gemini_model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "        \n",
    "        # Initialize embeddings (free HuggingFace model) with error handling\n",
    "        try:\n",
    "            print(\"Initializing embeddings...\")\n",
    "            #self.embeddings = HuggingFaceEmbeddings(\n",
    "            #    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "            #    model_kwargs={'device': 'cpu'}  # Explicitly use CPU\n",
    "            #)\n",
    "            openai_api_key = \"\"\n",
    "            self.embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "            print(\"Embeddings initialized successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing embeddings: {e}\")\n",
    "            raise e\n",
    "        \n",
    "        # Initialize ChromaDB (free vector database)\n",
    "        try:\n",
    "            print(\"Initializing ChromaDB...\")\n",
    "            self.chroma_client = chromadb.PersistentClient(\n",
    "                path=\"./knowledge_base\",\n",
    "                settings=Settings(anonymized_telemetry=False, allow_reset=True)\n",
    "            )\n",
    "            print(\"ChromaDB initialized successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing ChromaDB: {e}\")\n",
    "            raise e\n",
    "        \n",
    "        # Create collections for different content types\n",
    "        try:\n",
    "            self.text_collection = self.chroma_client.get_or_create_collection(\n",
    "                name=\"text_documents\",\n",
    "                metadata={\"description\": \"Text-based documents\"}\n",
    "            )\n",
    "            \n",
    "            self.image_collection = self.chroma_client.get_or_create_collection(\n",
    "                name=\"image_documents\", \n",
    "                metadata={\"description\": \"Image-based documents\"}\n",
    "            )\n",
    "            print(\"Collections created successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating collections: {e}\")\n",
    "            raise e\n",
    "        \n",
    "        # Text splitter for chunking documents\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200,\n",
    "            length_function=len\n",
    "        )\n",
    "        \n",
    "        # Session memory storage (in-memory for Phase 1)\n",
    "        self.session_memory = {}\n",
    "    \n",
    "    def extract_text_from_file(self, file_path: str, file_type: str) -> str:\n",
    "        \"\"\"\n",
    "        Extract text from various file formats\n",
    "        \n",
    "        Args:\n",
    "            file_path: Path to the file\n",
    "            file_type: Type of file (pdf, docx, pptx, txt)\n",
    "            \n",
    "        Returns:\n",
    "            Extracted text content\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if file_type == 'pdf':\n",
    "                with open(file_path, 'rb') as file:\n",
    "                    pdf_reader = PyPDF2.PdfReader(file)\n",
    "                    text = \"\"\n",
    "                    for page in pdf_reader.pages:\n",
    "                        text += page.extract_text() + \"\\n\"\n",
    "                    return text\n",
    "                        \n",
    "            elif file_type == 'docx':\n",
    "                doc = Document(file_path)\n",
    "                text = \"\"\n",
    "                for paragraph in doc.paragraphs:\n",
    "                    text += paragraph.text + \"\\n\"\n",
    "                return text\n",
    "                \n",
    "            elif file_type == 'pptx':\n",
    "                prs = Presentation(file_path)\n",
    "                text = \"\"\n",
    "                for slide in prs.slides:\n",
    "                    for shape in slide.shapes:\n",
    "                        if hasattr(shape, \"text\"):\n",
    "                            text += shape.text + \"\\n\"\n",
    "                return text\n",
    "                \n",
    "            elif file_type == 'txt':\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    return file.read()\n",
    "                    \n",
    "        except Exception as e:\n",
    "            return f\"Error extracting text: {str(e)}\"\n",
    "    \n",
    "    def process_image_with_gemini(self, image_path: str) -> str:\n",
    "        \"\"\"\n",
    "        Extract text/information from images using Gemini Vision\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to the image file\n",
    "            \n",
    "        Returns:\n",
    "            Extracted text and description\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Open and process image\n",
    "            image = Image.open(image_path)\n",
    "            \n",
    "            # Use Gemini to analyze the image\n",
    "            prompt = \"\"\"\n",
    "            Analyze this image and provide:\n",
    "            1. Any text visible in the image (OCR)\n",
    "            2. A detailed description of the content\n",
    "            3. Key information or concepts shown\n",
    "            4. Context that might be useful for search\n",
    "            \n",
    "            Format your response clearly with these sections.\n",
    "            \"\"\"\n",
    "            \n",
    "            response = self.gemini_model.generate_content([prompt, image])\n",
    "            return response.text\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error processing image: {str(e)}\"\n",
    "    \n",
    "    def add_document(self, file_path: str, file_name: str, session_id: str = \"default\") -> str:\n",
    "        \"\"\"\n",
    "        Add a document to the knowledge base\n",
    "        \n",
    "        Args:\n",
    "            file_path: Path to the document\n",
    "            file_name: Original name of the file\n",
    "            session_id: Session identifier for memory\n",
    "            \n",
    "        Returns:\n",
    "            Status message\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Determine file type\n",
    "            file_extension = file_name.lower().split('.')[-1]\n",
    "            \n",
    "            # Process based on file type\n",
    "            if file_extension in ['pdf', 'docx', 'pptx', 'txt']:\n",
    "                # Text-based document processing\n",
    "                content = self.extract_text_from_file(file_path, file_extension)\n",
    "                \n",
    "                if content and not content.startswith(\"Error\"):\n",
    "                    # Split content into chunks\n",
    "                    chunks = self.text_splitter.split_text(content)\n",
    "                    \n",
    "                    # Generate embeddings and store\n",
    "                    for i, chunk in enumerate(chunks):\n",
    "                        try:\n",
    "                            # Create unique ID for each chunk\n",
    "                            chunk_id = f\"{file_name}_{i}_{int(datetime.now().timestamp())}\"\n",
    "                            \n",
    "                            # Generate embedding with error handling\n",
    "                            embedding = self.embeddings.embed_query(chunk)\n",
    "                            \n",
    "                            # Store in ChromaDB\n",
    "                            self.text_collection.add(\n",
    "                                embeddings=[embedding],\n",
    "                                documents=[chunk],\n",
    "                                metadatas=[{\n",
    "                                    \"file_name\": file_name,\n",
    "                                    \"file_type\": file_extension,\n",
    "                                    \"chunk_index\": i,\n",
    "                                    \"session_id\": session_id,\n",
    "                                    \"timestamp\": datetime.now().isoformat()\n",
    "                                }],\n",
    "                                ids=[chunk_id]\n",
    "                            )\n",
    "                        except Exception as chunk_error:\n",
    "                            print(f\"Error processing chunk {i}: {chunk_error}\")\n",
    "                            continue\n",
    "                    \n",
    "                    # Update session memory\n",
    "                    if session_id not in self.session_memory:\n",
    "                        self.session_memory[session_id] = []\n",
    "                    \n",
    "                    self.session_memory[session_id].append({\n",
    "                        \"file_name\": file_name,\n",
    "                        \"file_type\": file_extension,\n",
    "                        \"chunks_count\": len(chunks),\n",
    "                        \"timestamp\": datetime.now().isoformat()\n",
    "                    })\n",
    "                    \n",
    "                    return f\"✅ Successfully processed {file_name} ({len(chunks)} chunks)\"\n",
    "                else:\n",
    "                    return f\"❌ Failed to extract content from {file_name}\"\n",
    "                    \n",
    "            elif file_extension in ['jpg', 'jpeg', 'png', 'gif', 'bmp']:\n",
    "                # Image processing\n",
    "                content = self.process_image_with_gemini(file_path)\n",
    "                \n",
    "                if content and not content.startswith(\"Error\"):\n",
    "                    # Generate embedding for image content\n",
    "                    embedding = self.embeddings.embed_query(content)\n",
    "                    \n",
    "                    # Create unique ID\n",
    "                    doc_id = f\"{file_name}_{int(datetime.now().timestamp())}\"\n",
    "                    \n",
    "                    # Store in image collection\n",
    "                    self.image_collection.add(\n",
    "                        embeddings=[embedding],\n",
    "                        documents=[content],\n",
    "                        metadatas=[{\n",
    "                            \"file_name\": file_name,\n",
    "                            \"file_type\": \"image\",\n",
    "                            \"session_id\": session_id,\n",
    "                            \"timestamp\": datetime.now().isoformat()\n",
    "                        }],\n",
    "                        ids=[doc_id]\n",
    "                    )\n",
    "                    \n",
    "                    # Update session memory\n",
    "                    if session_id not in self.session_memory:\n",
    "                        self.session_memory[session_id] = []\n",
    "                    \n",
    "                    self.session_memory[session_id].append({\n",
    "                        \"file_name\": file_name,\n",
    "                        \"file_type\": \"image\",\n",
    "                        \"timestamp\": datetime.now().isoformat()\n",
    "                    })\n",
    "                    \n",
    "                    return f\"✅ Successfully processed image {file_name}\"\n",
    "                else:\n",
    "                    return f\"❌ Failed to process image {file_name}\"\n",
    "            else:\n",
    "                return f\"❌ Unsupported file type: {file_extension}\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            return f\"❌ Error processing {file_name}: {str(e)}\"\n",
    "    \n",
    "    def search_knowledge_base(self, query: str, session_id: str = \"default\", top_k: int = 5) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Search the knowledge base for relevant information\n",
    "        \n",
    "        Args:\n",
    "            query: User's search query\n",
    "            session_id: Session identifier\n",
    "            top_k: Number of top results to return\n",
    "            \n",
    "        Returns:\n",
    "            List of relevant documents with metadata\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Generate query embedding\n",
    "            query_embedding = self.embeddings.embed_query(query)\n",
    "            \n",
    "            # Search in text collection\n",
    "            text_results = self.text_collection.query(\n",
    "                query_embeddings=[query_embedding],\n",
    "                n_results=max(1, top_k//2),\n",
    "                where={\"session_id\": session_id} if session_id in self.session_memory else None\n",
    "            )\n",
    "            \n",
    "            # Search in image collection  \n",
    "            image_results = self.image_collection.query(\n",
    "                query_embeddings=[query_embedding],\n",
    "                n_results=max(1, top_k//2),\n",
    "                where={\"session_id\": session_id} if session_id in self.session_memory else None\n",
    "            )\n",
    "            \n",
    "            # Combine and format results\n",
    "            all_results = []\n",
    "            \n",
    "            # Process text results\n",
    "            if text_results['documents'] and text_results['documents'][0]:\n",
    "                for i, doc in enumerate(text_results['documents'][0]):\n",
    "                    all_results.append({\n",
    "                        'content': doc,\n",
    "                        'metadata': text_results['metadatas'][0][i],\n",
    "                        'distance': text_results['distances'][0][i],\n",
    "                        'type': 'text'\n",
    "                    })\n",
    "            \n",
    "            # Process image results\n",
    "            if image_results['documents'] and image_results['documents'][0]:\n",
    "                for i, doc in enumerate(image_results['documents'][0]):\n",
    "                    all_results.append({\n",
    "                        'content': doc,\n",
    "                        'metadata': image_results['metadatas'][0][i],\n",
    "                        'distance': image_results['distances'][0][i],\n",
    "                        'type': 'image'\n",
    "                    })\n",
    "            \n",
    "            # Sort by relevance (distance)\n",
    "            all_results.sort(key=lambda x: x['distance'])\n",
    "            \n",
    "            return all_results[:top_k]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Search error: {e}\")\n",
    "            return [{\"content\": f\"Search error: {str(e)}\", \"metadata\": {}, \"distance\": 1.0, \"type\": \"error\"}]\n",
    "    \n",
    "    def generate_answer(self, query: str, session_id: str = \"default\") -> str:\n",
    "        \"\"\"\n",
    "        Generate an answer using retrieved context and Gemini\n",
    "        \n",
    "        Args:\n",
    "            query: User's question\n",
    "            session_id: Session identifier\n",
    "            \n",
    "        Returns:\n",
    "            Generated answer\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Search for relevant documents\n",
    "            relevant_docs = self.search_knowledge_base(query, session_id)\n",
    "            \n",
    "            if not relevant_docs or all(doc['type'] == 'error' for doc in relevant_docs):\n",
    "                return \"I couldn't find relevant information in your knowledge base. Please upload some documents first.\"\n",
    "            \n",
    "            # Prepare context from retrieved documents\n",
    "            context = \"\"\n",
    "            sources = []\n",
    "            \n",
    "            for i, doc in enumerate(relevant_docs):\n",
    "                if doc['type'] != 'error':\n",
    "                    context += f\"\\nDocument {i+1} ({doc['type']}) from {doc['metadata'].get('file_name', 'Unknown')}:\\n\"\n",
    "                    context += doc['content'][:500] + \"...\\n\"  # Limit context length\n",
    "                    sources.append(doc['metadata'].get('file_name', 'Unknown'))\n",
    "            \n",
    "            if not context:\n",
    "                return \"I couldn't find relevant information in your knowledge base. Please upload some documents first.\"\n",
    "            \n",
    "            # Create prompt for Gemini\n",
    "            prompt = f\"\"\"\n",
    "            Based on the following context from the user's knowledge base, please answer the question.\n",
    "            \n",
    "            Context:\n",
    "            {context}\n",
    "            \n",
    "            Question: {query}\n",
    "            \n",
    "            Instructions:\n",
    "            1. Provide a comprehensive answer based on the context\n",
    "            2. If the context doesn't contain enough information, mention what's missing\n",
    "            3. Cite the source documents when relevant\n",
    "            4. Be conversational and helpful\n",
    "            \n",
    "            Answer:\n",
    "            \"\"\"\n",
    "            \n",
    "            # Generate response using Gemini\n",
    "            response = self.gemini_model.generate_content(prompt)\n",
    "            \n",
    "            # Add sources information\n",
    "            if sources:\n",
    "                sources_text = f\"\\n\\n📚 **Sources:** {', '.join(set(sources))}\"\n",
    "                return response.text + sources_text\n",
    "            else:\n",
    "                return response.text\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error generating answer: {str(e)}\"\n",
    "    \n",
    "    def get_session_info(self, session_id: str = \"default\") -> str:\n",
    "        \"\"\"\n",
    "        Get information about the current session\n",
    "        \n",
    "        Args:\n",
    "            session_id: Session identifier\n",
    "            \n",
    "        Returns:\n",
    "            Session information as formatted string\n",
    "        \"\"\"\n",
    "        if session_id not in self.session_memory:\n",
    "            return \"No documents uploaded in this session.\"\n",
    "        \n",
    "        docs = self.session_memory[session_id]\n",
    "        info = f\"📁 **Session Documents ({len(docs)} files):**\\n\\n\"\n",
    "        \n",
    "        for doc in docs:\n",
    "            info += f\"• {doc['file_name']} ({doc['file_type']}) - {doc['timestamp'][:19]}\\n\"\n",
    "            if 'chunks_count' in doc:\n",
    "                info += f\"  └── {doc['chunks_count']} text chunks\\n\"\n",
    "        \n",
    "        return info\n",
    "\n",
    "# Initialize the RAG system (will be done in Gradio interface)\n",
    "rag_system = None\n",
    "\n",
    "def initialize_system(gemini_key: str, openai_key: str) -> str:\n",
    "    \"\"\"Initialize the RAG system with Gemini API key\"\"\"\n",
    "    global rag_system\n",
    "    if not gemini_key:\n",
    "        return \"❌ Please provide a Gemini API key\"\n",
    "    if not openai_key:\n",
    "        return \"❌ Please provide a OpenAI API key\"\n",
    "    \n",
    "    try:\n",
    "        print(\"Starting system initialization...\")\n",
    "        rag_system = MultimodalRAG(gemini_key,openai_key)\n",
    "        print(\"System initialization completed!\")\n",
    "        return \"✅ System initialized successfully!\"\n",
    "    except Exception as e:\n",
    "        error_msg = f\"❌ Error initializing system: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "\n",
    "def upload_document(files, session_id: str = \"default\") -> str:\n",
    "    \"\"\"Handle document upload in Gradio\"\"\"\n",
    "    if rag_system is None:\n",
    "        return \"❌ Please initialize the system with your API key first\"\n",
    "    \n",
    "    if not files:\n",
    "        return \"❌ No files uploaded\"\n",
    "    \n",
    "    results = []\n",
    "    for file in files:\n",
    "        result = rag_system.add_document(file.name, os.path.basename(file.name), session_id)\n",
    "        results.append(result)\n",
    "    \n",
    "    return \"\\n\".join(results)\n",
    "\n",
    "def ask_question(question: str, session_id: str = \"default\") -> str:\n",
    "    \"\"\"Handle question answering in Gradio\"\"\"\n",
    "    if rag_system is None:\n",
    "        return \"❌ Please initialize the system with your API key first\"\n",
    "    \n",
    "    if not question:\n",
    "        return \"❌ Please ask a question\"\n",
    "    \n",
    "    return rag_system.generate_answer(question, session_id)\n",
    "\n",
    "def get_session_status(session_id: str = \"default\") -> str:\n",
    "    \"\"\"Get session status for Gradio\"\"\"\n",
    "    if rag_system is None:\n",
    "        return \"❌ System not initialized\"\n",
    "    \n",
    "    return rag_system.get_session_info(session_id)\n",
    "\n",
    "# Create Gradio Interface\n",
    "def create_gradio_interface():\n",
    "    \"\"\"Create the Gradio web interface\"\"\"\n",
    "    \n",
    "    with gr.Blocks(title=\"Enterprise Knowledge Assistant - Phase 1\", theme=gr.themes.Soft()) as demo:\n",
    "        gr.Markdown(\"\"\"\n",
    "        # 🧠 Enterprise Knowledge Assistant (Phase 1)\n",
    "        \n",
    "        Upload documents (PDF, DOCX, PPTX, TXT, Images) and ask questions about their content.\n",
    "        The system uses multimodal RAG to understand both text and visual content.\n",
    "        \n",
    "        **Note:** Make sure you have installed: `pip install sentence-transformers`\n",
    "        \"\"\")\n",
    "        \n",
    "        with gr.Tab(\"🔧 Setup\"):\n",
    "            gr.Markdown(\"### Initialize the System\")\n",
    "            api_key_input = gr.Textbox(\n",
    "                label=\"Gemini API Key\", \n",
    "                placeholder=\"Enter your Gemini API key here...\",\n",
    "                type=\"password\"\n",
    "            )\n",
    "            openai_key_input = gr.Textbox(\n",
    "            label=\"OpenAI API Key\", \n",
    "            placeholder=\"Enter your OpenAI API key here...\",\n",
    "             type=\"password\"\n",
    "            )\n",
    "\n",
    "            init_btn = gr.Button(\"Initialize System\", variant=\"primary\")\n",
    "            init_status = gr.Textbox(label=\"Status\", interactive=False)\n",
    "            \n",
    "            init_btn.click(\n",
    "                fn=initialize_system,\n",
    "                inputs=[api_key_input,openai_key_input],\n",
    "                outputs=[init_status]\n",
    "            )\n",
    "        \n",
    "        with gr.Tab(\"📁 Upload Documents\"):\n",
    "            gr.Markdown(\"### Upload Your Documents\")\n",
    "            session_input = gr.Textbox(\n",
    "                label=\"Session ID\", \n",
    "                value=\"default\",\n",
    "                placeholder=\"Enter session ID (optional)\"\n",
    "            )\n",
    "            \n",
    "            file_upload = gr.Files(\n",
    "                label=\"Upload Documents\",\n",
    "                file_count=\"multiple\",\n",
    "                file_types=[\".pdf\", \".docx\", \".pptx\", \".txt\", \".jpg\", \".jpeg\", \".png\", \".gif\", \".bmp\"]\n",
    "            )\n",
    "            \n",
    "            upload_btn = gr.Button(\"Process Documents\", variant=\"primary\")\n",
    "            upload_status = gr.Textbox(label=\"Upload Status\", interactive=False, lines=5)\n",
    "            \n",
    "            upload_btn.click(\n",
    "                fn=upload_document,\n",
    "                inputs=[file_upload, session_input],\n",
    "                outputs=[upload_status]\n",
    "            )\n",
    "        \n",
    "        with gr.Tab(\"🤖 Ask Questions\"):\n",
    "            gr.Markdown(\"### Query Your Knowledge Base\")\n",
    "            \n",
    "            session_query = gr.Textbox(\n",
    "                label=\"Session ID\", \n",
    "                value=\"default\",\n",
    "                placeholder=\"Enter session ID\"\n",
    "            )\n",
    "            \n",
    "            question_input = gr.Textbox(\n",
    "                label=\"Your Question\",\n",
    "                placeholder=\"Ask anything about your uploaded documents...\",\n",
    "                lines=3\n",
    "            )\n",
    "            \n",
    "            ask_btn = gr.Button(\"Get Answer\", variant=\"primary\")\n",
    "            answer_output = gr.Textbox(\n",
    "                label=\"Answer\", \n",
    "                interactive=False, \n",
    "                lines=10\n",
    "            )\n",
    "            \n",
    "            ask_btn.click(\n",
    "                fn=ask_question,\n",
    "                inputs=[question_input, session_query],\n",
    "                outputs=[answer_output]\n",
    "            )\n",
    "        \n",
    "        with gr.Tab(\"📊 Session Info\"):\n",
    "            gr.Markdown(\"### Session Status\")\n",
    "            \n",
    "            session_status_input = gr.Textbox(\n",
    "                label=\"Session ID\", \n",
    "                value=\"default\"\n",
    "            )\n",
    "            \n",
    "            status_btn = gr.Button(\"Check Status\")\n",
    "            status_output = gr.Textbox(\n",
    "                label=\"Session Information\", \n",
    "                interactive=False, \n",
    "                lines=8\n",
    "            )\n",
    "            \n",
    "            status_btn.click(\n",
    "                fn=get_session_status,\n",
    "                inputs=[session_status_input],\n",
    "                outputs=[status_output]\n",
    "            )\n",
    "        \n",
    "        gr.Markdown(\"\"\"\n",
    "        ### 🔧 Troubleshooting\n",
    "        If you encounter import errors:\n",
    "        1. Make sure you're in your virtual environment\n",
    "        2. Run: `pip install sentence-transformers torch transformers`\n",
    "        3. For ChromaDB issues: `pip install chromadb --upgrade`\n",
    "        \"\"\")\n",
    "    \n",
    "    return demo\n",
    "\n",
    "# Launch the application\n",
    "if __name__ == \"__main__\":\n",
    "    demo = create_gradio_interface()\n",
    "    demo.launch(\n",
    "        server_name=\"0.0.0.0\",\n",
    "        server_port=7860,\n",
    "        share=True  # Creates public URL for sharing\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5932579",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
