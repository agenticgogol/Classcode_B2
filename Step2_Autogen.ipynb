{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbb3c8a5",
   "metadata": {},
   "source": [
    "### Autogen uses async functionality for real time agent interactions\n",
    "- If Agent calls an API , we can keep it in background and carry on with other tasks while it waits for response\n",
    "- Synchronous -1 by 1 sequential execution\n",
    "- async - co routine execution (multiple task execution simultaneously)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dfbe9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brewing Coffee\n",
      "Coffee Ready\n",
      "Toasting Bread\n",
      "bread Ready\n",
      "Time : 5.01 minutes\n"
     ]
    }
   ],
   "source": [
    "# Sync process\n",
    "import time\n",
    "def brew_coffee():\n",
    "    print(\"Brewing Coffee\")\n",
    "    time.sleep(3) # 3 Minutes\n",
    "    print(\"Coffee Ready\")\n",
    "\n",
    "def toast_bread():\n",
    "    print(\"Toasting Bread\")\n",
    "    time.sleep(2) # 2 Minutes\n",
    "    print(\"bread Ready\")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "coffee = brew_coffee()\n",
    "# time.sleep(2)\n",
    "bread = toast_bread()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "\n",
    "print(f\"Time : {end - start:.2f} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45cbfb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Brewing Coffee\n",
      "Start Toasting bread\n",
      "Bread Ready\n",
      "Coffee Ready\n",
      "Time : 3.00 minutes\n"
     ]
    }
   ],
   "source": [
    "# Async process\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def brew_coffee():\n",
    "    print(\"Starting Brewing Coffee\")\n",
    "    await asyncio.sleep(3)\n",
    "    print(\"Coffee Ready\")\n",
    "\n",
    "async def toast_bread():\n",
    "    print(\"Start Toasting bread\")\n",
    "    await asyncio.sleep(2)\n",
    "    print(\"Bread Ready\")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "coffee = brew_coffee()\n",
    "bread = toast_bread()\n",
    "\n",
    "results = await asyncio.gather(coffee,bread)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Time : {end - start:.2f} minutes\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53dece3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Brewing Coffee\n",
      "Start Toasting bread\n",
      "Bread Ready\n",
      "Coffee Ready\n",
      "Time : 3.01 minutes\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def brew_coffee_async():\n",
    "    print(\"Starting Brewing Coffee\")\n",
    "    await asyncio.sleep(3)\n",
    "    print(\"Coffee Ready\")\n",
    "\n",
    "async def toast_bread_async():\n",
    "    print(\"Start Toasting bread\")\n",
    "    await asyncio.sleep(2)\n",
    "    print(\"Bread Ready\")\n",
    "\n",
    "async def main_individual():\n",
    "    start = time.time()\n",
    "    coffee_task = asyncio.create_task(brew_coffee_async())\n",
    "    bread_task = asyncio.create_task(toast_bread_async())\n",
    "\n",
    "    coffee = await coffee_task\n",
    "    bagel = await bread_task\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"Time : {end - start:.2f} minutes\")\n",
    "\n",
    "\n",
    "await (main_individual())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74129d69",
   "metadata": {},
   "source": [
    "# Now more on AgentChat ( What we already saw)\n",
    "- Agentchat gives us a async powered way to handle agent conversation\n",
    "- It helps us to define agents and enable them to chat , collaborate and solve tasks\n",
    "- event driven i.e response to task as they come\n",
    "- features are - customization with prompts we can do , we can connect it to LLMs \n",
    "- This is a high level API makes development is very easy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d28926",
   "metadata": {},
   "source": [
    "# Customizing the Agents and prompt engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02f06864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting the future of international relations involves a good deal of uncertainty and speculation. However, a few trends hint at the possible trajectory of the relationship between India and the United States. \n",
      "\n",
      "1. Shared Democratic Values: As two of the world's largest democracies, the US and India share many values, such as the importance of a democratic government and the rule of law. These shared values remain a cornerstone in their partnership.\n",
      "\n",
      "2. Strategic Partner: India's location makes it a key strategic partner for the US, especially in relation to China. US regards India as an important partner in the Indo-Pacific region. If tensions between the US and China continue to escalate, the strategic significance of India will likely increase.\n",
      "\n",
      "3. Trade Relations: Economic and trade relations between the two countries have been a friction point. Both sides have expressed interest in a trade deal, but disagreements over specific terms have hampered progress. The future relationship will be determined, in part, by whether they can find a mutually agreeable solution to these trade disputes.\n",
      "\n",
      "4. Climate Change Cooperation: US return to the Paris Agreement under President Biden could lead to increased cooperation with India on issues like climate change, clean energy and green technology.\n",
      "\n",
      "5. Technology and Innovation: The two countries continue to collaborate in the field of technology and innovation. Future ties could be determined by cooperation in areas like digital technology, AI, and cybersecurity.\n",
      "\n",
      "6. Diaspora Ties: The Indian diaspora in the US is significant and continues to grow, strengthening cultural and demographic ties.\n",
      "\n",
      "However, there are challenges such as India's resistance to align strictly with any global power, issues of human rights, difference in opinion about Iran, Russia and other global affairs.\n",
      "\n",
      "In conclusion, while it is tricky to predict the future, the above-mentioned factors will likely shape the future trajectory of Indo-US relations. The relationship has overall been on an upward trend, with increasing strategic and global cooperation, but it also faces a number of challenges.\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "model_client = OpenAIChatCompletionClient(model='gpt-4', api_key=api_key)\n",
    "\n",
    "### Agent Customization\n",
    "\n",
    "#- We can assign a role to our agent\n",
    "#- help in fitting agent to specific use case\n",
    "# This will help us in multi agent frameworks later\n",
    "\n",
    "asssistant = AssistantAgent(\n",
    "    name = 'politicalscience_expert',\n",
    "    model_client=model_client,\n",
    "    description='A knowledgeable assistant with expertise in political science',\n",
    "    system_message='You are a political science expert with deep knowledge of world politics. Provide detailed and accuragte answers about political events,figures and timelines and explanation'\n",
    ")\n",
    "\n",
    "async def test_politicalscience_expert():\n",
    "    result = await asssistant.run(task = 'What is the future of India and US relationship?')\n",
    "    print(result.messages[-1].content)\n",
    "\n",
    "await test_politicalscience_expert()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1efc60",
   "metadata": {},
   "source": [
    "# Using tools for MS Autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e2ebef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in Toronto is cloudy with a high of -5 degree celsius.\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "model_client = OpenAIChatCompletionClient(model='gpt-4', api_key=api_key)\n",
    "\n",
    "def get_weather(city:str) -> str:\n",
    "    \"\"\"\n",
    "    Fetches the weather for a given city.\n",
    "    This is a placeholder function and should be replaced with actual weather fetching logic.\n",
    "    For example, you could use a weather API to get real-time data.\n",
    "    :param city: Name of the city to fetch weather for.\n",
    "    :return: Weather information as a string.\n",
    "    \"\"\"\n",
    "    # Placeholder function to simulate weather fetching\n",
    "    return f\"The weather in {city} is cloudy with a high of -5 degree celsius.\"\n",
    "\n",
    "assistant = AssistantAgent(\n",
    "    name = 'weather_assistant',\n",
    "    model_client=model_client,\n",
    "    system_message='You are a weather assistant, Use the right tool when asked about the weather in a city.',\n",
    "    tools= [get_weather]\n",
    ")\n",
    "\n",
    "async def test_weather_tool():\n",
    "    result = await assistant.run(task = 'What is the weather in Toronto?')\n",
    "    print(result.messages[-1].content)\n",
    "\n",
    "await test_weather_tool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e0f87b",
   "metadata": {},
   "source": [
    "# Messages in Autogen\n",
    "-  We can imagine messages as the way agent communicate each other - chatting with our Friend. \n",
    "\n",
    "- When we communicate with the agents -----> sending a message\n",
    "- when it responds ---> it too sends a message\n",
    "\n",
    "- TextMessage \n",
    "- ImageMessage\n",
    "- ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "256db3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Direct Interaction Test ---\n",
      "Assistant's response:\n",
      "As of October 2023, the Prime Minister of India is Narendra Modi. He has been in office since May 26, 2014, after leading the Bharatiya Janata Party (BJP) to victory in the general elections.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from autogen_agentchat.agents import AssistantAgent,UserProxyAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.messages import TextMessage, MultiModalMessage\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_core import Image as AGImage\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if api_key is None:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable is not set.\")\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(model='gpt-4o', api_key=api_key)\n",
    "\n",
    "# Assistant Agent\n",
    "assistant_agent = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=model_client,\n",
    "    system_message='You are a helpful assistant. Answer questions accurately and provide detailed information.'\n",
    ")\n",
    "\n",
    "# User Proxy Agent\n",
    "user_proxy_agent = UserProxyAgent(\n",
    "    name=\"user_proxy\"\n",
    ")\n",
    "async def test_direct_interaction():\n",
    "    print(\"\\n--- Direct Interaction Test ---\")\n",
    "    \n",
    "    # User proxy sends message to assistant\n",
    "    text_msg = TextMessage(content='Who is the prime minister of India? Please provide current information.', source='user_proxy')\n",
    "    \n",
    "    # Assistant processes the message\n",
    "    result = await assistant_agent.run(task=text_msg)\n",
    "    \n",
    "    print(\"Assistant's response:\")\n",
    "    print(result.messages[-1].content)\n",
    "\n",
    "await test_direct_interaction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c420d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose interaction mode:\n",
      "1. Interactive chat (continuous conversation)\n",
      "2. Single question mode\n",
      "=== Welcome to Interactive AutoGen Chat ===\n",
      "Type 'quit', 'exit', or 'bye' to end the conversation\n",
      "==================================================\n",
      "\n",
      "Thinking...\n",
      "\n",
      "Assistant: AI in retail enhances customer experiences through personalized recommendations and efficient customer service while optimizing operations by streamlining inventory management and demand forecasting. By analyzing vast amounts of data, AI enables retailers to offer targeted marketing strategies and improve supply chain efficiency.\n",
      "--------------------------------------------------\n",
      "\n",
      "Thinking...\n",
      "\n",
      "Assistant: The last question you asked was about the role of AI in retail, specifically requesting a two-sentence explanation.\n",
      "--------------------------------------------------\n",
      "\n",
      "Goodbye! Thanks for chatting!\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from autogen_agentchat.agents import AssistantAgent, UserProxyAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.messages import TextMessage, MultiModalMessage\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_core import Image as AGImage\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if api_key is None:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable is not set.\")\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(model='gpt-4o', api_key=api_key)\n",
    "\n",
    "# Assistant Agent\n",
    "assistant_agent = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=model_client,\n",
    "    system_message='You are a helpful assistant. Answer questions accurately and provide detailed information.'\n",
    ")\n",
    "\n",
    "# User Proxy Agent\n",
    "user_proxy_agent = UserProxyAgent(\n",
    "    name=\"user_proxy\"\n",
    ")\n",
    "\n",
    "async def interactive_chat():\n",
    "    \"\"\"Interactive chat function that allows users to input questions\"\"\"\n",
    "    print(\"=== Welcome to Interactive AutoGen Chat ===\")\n",
    "    print(\"Type 'quit', 'exit', or 'bye' to end the conversation\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            # Get user input\n",
    "            user_question = input(\"\\nYou: \").strip()\n",
    "            \n",
    "            # Check for exit commands\n",
    "            if user_question.lower() in ['quit', 'exit', 'bye', 'q']:\n",
    "                print(\"\\nGoodbye! Thanks for chatting!\")\n",
    "                break\n",
    "            \n",
    "            # Skip empty inputs\n",
    "            if not user_question:\n",
    "                print(\"Please enter a question or type 'quit' to exit.\")\n",
    "                continue\n",
    "            \n",
    "            print(\"\\nThinking...\")\n",
    "            \n",
    "            # Create message and get response\n",
    "            text_msg = TextMessage(content=user_question, source='user_proxy')\n",
    "            result = await assistant_agent.run(task=text_msg)\n",
    "            \n",
    "            # Display assistant's response\n",
    "            print(f\"\\nAssistant: {result.messages[-1].content}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nChat interrupted by user. Goodbye!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError occurred: {e}\")\n",
    "            print(\"Please try again or type 'quit' to exit.\")\n",
    "\n",
    "async def single_question_mode():\n",
    "    \"\"\"Single question mode - ask one question and get answer\"\"\"\n",
    "    user_question = input(\"Enter your question: \").strip()\n",
    "    \n",
    "    if not user_question:\n",
    "        print(\"No question provided.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nProcessing your question...\")\n",
    "    \n",
    "    try:\n",
    "        text_msg = TextMessage(content=user_question, source='user_proxy')\n",
    "        result = await assistant_agent.run(task=text_msg)\n",
    "        \n",
    "        print(f\"\\nAnswer: {result.messages[-1].content}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "async def main():\n",
    "    \"\"\"Main function to choose interaction mode\"\"\"\n",
    "    print(\"Choose interaction mode:\")\n",
    "    print(\"1. Interactive chat (continuous conversation)\")\n",
    "    print(\"2. Single question mode\")\n",
    "    \n",
    "    while True:\n",
    "        choice = input(\"\\nEnter your choice (1 or 2): \").strip()\n",
    "        \n",
    "        if choice == '1':\n",
    "            await interactive_chat()\n",
    "            break\n",
    "        elif choice == '2':\n",
    "            await single_question_mode()\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid choice. Please enter 1 or 2.\")\n",
    "\n",
    "# Run the main function\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "653c0412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of October 2023, the Prime Minister of India is Narendra Modi. He has been in office since May 26, 2014.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.messages import TextMessage,MultiModalMessage\n",
    "from autogen_core import Image as AGImage\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if api_key is None:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable is not set.\")\n",
    "model_client = OpenAIChatCompletionClient(model='gpt-4o',api_key=api_key)\n",
    "\n",
    "# Simple text message \n",
    "agent = AssistantAgent(\n",
    "    name = \"text_agent\",\n",
    "    model_client=model_client,\n",
    "    system_message='You are a helpful assistant. answer question accurately'\n",
    ")\n",
    "\n",
    "async def test_text_messages():\n",
    "    text_msg = TextMessage(content = 'Who is prime minister of India?', source='user')\n",
    "    result = await agent.run(task=text_msg)\n",
    "    print(result.messages[-1].content)\n",
    "\n",
    "await test_text_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79fff448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows a pair of white high-heeled shoes placed against a red, textured background with white splatters.\n"
     ]
    }
   ],
   "source": [
    "async def test_multi_modal():\n",
    "\n",
    "    response = requests.get('https://picsum.photos/id/21/200/300') # 23 for the image of folks\n",
    "    pil_image = Image.open(BytesIO(response.content))\n",
    "    ag_image = AGImage(pil_image)\n",
    "\n",
    "    multi_modal_msg = MultiModalMessage(\n",
    "        content = ['What is in the image?',ag_image],\n",
    "        source='user'\n",
    "    )\n",
    "\n",
    "    result = await agent.run(task=multi_modal_msg)\n",
    "    print(result.messages[-1].content)\n",
    "\n",
    "\n",
    "await test_multi_modal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aff89b4",
   "metadata": {},
   "source": [
    "# Mention about on_message() and on_messages_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ef7e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abb2e81",
   "metadata": {},
   "source": [
    "# Structured output via autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77a96aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mars, often referred to as the \"Red Planet,\" is the fourth planet from the Sun in our solar system. It has been a point of interest for scientists and astronomers for centuries due to its similarities and differences with Earth. Here are some key details about Mars:\n",
      "\n",
      "1. **Basic Characteristics:**\n",
      "   - **Diameter:** Approximately 6,779 kilometers (4,212 miles), making it about half the diameter of Earth.\n",
      "   - **Mass:** About 0.11 times that of Earth.\n",
      "   - **Surface Gravity:** Approximately 0.38 of Earth's gravity.\n",
      "   - **Length of Day:** A Martian day, or sol, is approximately 24.6 hours.\n",
      "   - **Length of Year:** About 687 Earth days.\n",
      "\n",
      "2. **Orbit and Rotation:**\n",
      "   - Mars has an elliptical orbit, leading to variation in its distance from the Sun, ranging from about 206 million km (128 million miles) to 249 million km (155 million miles).\n",
      "\n",
      "3. **Atmosphere:**\n",
      "   - The atmosphere is thin, composed mostly of carbon dioxide (95.3%), with traces of nitrogen, argon, oxygen, and water vapor.\n",
      "   - Surface pressure is less than 1% of Earth's, making it challenging for liquid water to exist on the surface.\n",
      "\n",
      "4. **Surface and Geography:**\n",
      "   - Known for its red appearance due to iron oxide, or rust, on its surface.\n",
      "   - Features include the largest volcano in the solar system, Olympus Mons, and the largest canyon, Valles Marineris.\n",
      "   - Evidence of past water flows, such as ancient river valleys and lakebeds.\n",
      "\n",
      "5. **Climate:**\n",
      "   - Mars is much colder than Earth, with average surface temperatures around -80 degrees Fahrenheit (-62 degrees Celsius).\n",
      "   - Temperatures can vary widely from day to night and across seasons.\n",
      "\n",
      "6. **Moons:**\n",
      "   - Mars has two small moons, Phobos and Deimos, thought to be captured asteroids.\n",
      "\n",
      "7. **Exploration:**\n",
      "   - Mars has been explored by various missions from different space agencies, including orbiters, landers, and rovers. Notable missions include NASAâ€™s rovers like Spirit, Opportunity, Curiosity, and Perseverance, as well as the Ingenuity helicopter.\n",
      "   - The exploration of Mars aims to understand its geology, climate, potential for life, and suitability for future human missions.\n",
      "\n",
      "8. **Scientific Interest:**\n",
      "   - Mars is a prime candidate in the search for past life because of its history of water presence.\n",
      "   - Understanding Mars' environment helps scientists learn more about the potential habitability of other planets.\n",
      "\n",
      "Mars continues to be a focus for future exploration, with ongoing and planned missions aiming to uncover more about its history, geology, and potential for sustaining life.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from pydantic import BaseModel\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class PlanetInfo(BaseModel):\n",
    "    name: str\n",
    "    color: str\n",
    "    distance_miles: int\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model = 'gpt-4o',\n",
    "    api_key=api_key,\n",
    "    response_format=PlanetInfo\n",
    "    )\n",
    "\n",
    "unstructured_model_client = OpenAIChatCompletionClient(\n",
    "    model = 'gpt-4o',\n",
    "    api_key=api_key,\n",
    "    # response_format=PlanetInfo\n",
    "    )\n",
    "\n",
    "agent = AssistantAgent(\n",
    "    name='planet_agent',\n",
    "    model_client=unstructured_model_client,\n",
    "    system_message=\"You are a helpful assistant that provides information about planets.\" \n",
    ")\n",
    "async def test_structured_output():\n",
    "    task = TextMessage(content = \"Please provide information about Mars.\",source='User')\n",
    "    result = await agent.run(task=task)\n",
    "    structured_response = result.messages[-1].content\n",
    "    print(structured_response)\n",
    "\n",
    "await test_structured_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e324efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\":\"Mars\",\"color\":\"Red\",\"distance_miles\":141600000}\n"
     ]
    }
   ],
   "source": [
    "agent = AssistantAgent(\n",
    "    name='planet_agent',\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a helpful assistant that provides information about planets.\"\n",
    ")\n",
    "async def test_structured_output():\n",
    "    task = TextMessage(content = \"Please provide information about Mars.\",source='User')\n",
    "    result = await agent.run(task=task)\n",
    "    structured_response = result.messages[-1].content\n",
    "    print(structured_response)\n",
    "\n",
    "await test_structured_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c26240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
