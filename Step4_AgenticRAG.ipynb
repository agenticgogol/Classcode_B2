{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85a82135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utsabchakraborty/Documents/Agentic_Class_Live/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7862\n",
      "* Running on public URL: https://e72407edced9e51655.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://e72407edced9e51655.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/7gw2rnq56ls5m4r1vbglz5r00000gn/T/ipykernel_42922/924450648.py:65: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  self.embeddings = OpenAIEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "# Phase 2: Agentic RAG System with Multi-Agent Architecture\n",
    "# Requirements: pip install gradio chromadb langchain google-generativeai openai PyPDF2 python-docx python-pptx pillow\n",
    "\n",
    "import os\n",
    "import io\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "import gradio as gr\n",
    "import google.generativeai as genai\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from PIL import Image\n",
    "import PyPDF2\n",
    "from docx import Document\n",
    "from pptx import Presentation\n",
    "\n",
    "# ------------------------------\n",
    "# Agent infrastructure\n",
    "# ------------------------------\n",
    "class AgentType(Enum):\n",
    "    RESEARCHER = \"researcher\"\n",
    "    SYNTHESIZER = \"synthesizer\"\n",
    "    FACT_CHECKER = \"fact_checker\"\n",
    "    FOLLOW_UP = \"follow_up\"\n",
    "    COORDINATOR = \"coordinator\"\n",
    "\n",
    "@dataclass\n",
    "class AgentResponse:\n",
    "    agent_type: AgentType\n",
    "    content: str\n",
    "    confidence: float\n",
    "    sources: List[str]\n",
    "    reasoning: str\n",
    "    follow_up_needed: bool = False\n",
    "\n",
    "@dataclass\n",
    "class ResearchTask:\n",
    "    query: str\n",
    "    context: str\n",
    "    agent_type: AgentType\n",
    "    priority: int = 1\n",
    "    dependencies: List[str] = None\n",
    "\n",
    "# ------------------------------\n",
    "# Agentic RAG System class\n",
    "# ------------------------------\n",
    "class AgenticRAG:\n",
    "    def __init__(self, gemini_api_key: str, openai_api_key: str):\n",
    "        \"\"\"\n",
    "        Initialize Agentic RAG:\n",
    "        - Gemini: reasoning LLM (google.generativeai)\n",
    "        - OpenAI: embeddings (OpenAIEmbeddings via langchain)\n",
    "        \"\"\"\n",
    "        # Configure Gemini (LLM)\n",
    "        genai.configure(api_key=gemini_api_key)\n",
    "        self.gemini_model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "        # Configure OpenAI embeddings\n",
    "        self.embeddings = OpenAIEmbeddings(\n",
    "            model=\"text-embedding-3-small\",\n",
    "            openai_api_key=openai_api_key\n",
    "        )\n",
    "\n",
    "        # Initialize ChromaDB (persistent)\n",
    "        self.chroma_client = chromadb.PersistentClient(\n",
    "            path=\"./agentic_knowledge_base\",\n",
    "            settings=Settings(anonymized_telemetry=False)\n",
    "        )\n",
    "\n",
    "        # Collections\n",
    "        self.text_collection = self.chroma_client.get_or_create_collection(\n",
    "            name=\"text_documents_v2\",\n",
    "            metadata={\"description\": \"Text-based documents with agent metadata\"}\n",
    "        )\n",
    "        self.image_collection = self.chroma_client.get_or_create_collection(\n",
    "            name=\"image_documents_v2\",\n",
    "            metadata={\"description\": \"Image-based documents with agent metadata\"}\n",
    "        )\n",
    "        self.agent_collection = self.chroma_client.get_or_create_collection(\n",
    "            name=\"agent_responses\",\n",
    "            metadata={\"description\": \"Agent responses and reasoning\"}\n",
    "        )\n",
    "\n",
    "        # Text splitter for ingestion\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=800,\n",
    "            chunk_overlap=150,\n",
    "            length_function=len\n",
    "        )\n",
    "\n",
    "        # Session & agent memory\n",
    "        self.session_memory: Dict[str, List[Dict[str, Any]]] = {}\n",
    "        self.agent_memory: Dict[str, List[Dict[str, Any]]] = {}\n",
    "\n",
    "    # ------------------------------\n",
    "    # Document / image extraction\n",
    "    # ------------------------------\n",
    "    def extract_text_from_file(self, file_path: str, file_type: str) -> str:\n",
    "        \"\"\"Extract text from PDF / DOCX / PPTX / TXT\"\"\"\n",
    "        try:\n",
    "            if file_type == 'pdf':\n",
    "                with open(file_path, 'rb') as f:\n",
    "                    reader = PyPDF2.PdfReader(f)\n",
    "                    pages_text = []\n",
    "                    for p in reader.pages:\n",
    "                        page_text = p.extract_text() or \"\"\n",
    "                        pages_text.append(page_text)\n",
    "                    return \"\\n\".join(pages_text)\n",
    "\n",
    "            elif file_type == 'docx':\n",
    "                doc = Document(file_path)\n",
    "                return \"\\n\".join([p.text for p in doc.paragraphs])\n",
    "\n",
    "            elif file_type == 'pptx':\n",
    "                prs = Presentation(file_path)\n",
    "                text = \"\"\n",
    "                for slide in prs.slides:\n",
    "                    for shape in slide.shapes:\n",
    "                        if hasattr(shape, \"text\"):\n",
    "                            text += shape.text + \"\\n\"\n",
    "                return text\n",
    "\n",
    "            elif file_type == 'txt':\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    return f.read()\n",
    "\n",
    "            else:\n",
    "                return f\"Error: Unsupported file type {file_type}\"\n",
    "        except Exception as e:\n",
    "            return f\"Error extracting text: {str(e)}\"\n",
    "\n",
    "    def process_image_with_gemini(self, image_path: str) -> str:\n",
    "        \"\"\"Use Gemini Vision to analyze image and return textual analysis\"\"\"\n",
    "        try:\n",
    "            image = Image.open(image_path)\n",
    "            prompt = (\n",
    "                \"Analyze this image and provide:\\n\"\n",
    "                \"1. Any visible text (OCR)\\n\"\n",
    "                \"2. A detailed description of the content\\n\"\n",
    "                \"3. Key information or concepts shown\\n\"\n",
    "                \"4. Useful context for search/retrieval\\n\\n\"\n",
    "                \"Format your response into clear sections.\"\n",
    "            )\n",
    "\n",
    "            # Gemini can accept multimodal inputs; we use generate_content with [prompt, image]\n",
    "            resp = self.gemini_model.generate_content([prompt, image])\n",
    "            return resp.text\n",
    "        except Exception as e:\n",
    "            return f\"Error processing image: {str(e)}\"\n",
    "\n",
    "    # ------------------------------\n",
    "    # Agents\n",
    "    # ------------------------------\n",
    "    async def research_agent(self, task: ResearchTask, session_id: str) -> AgentResponse:\n",
    "        try:\n",
    "            # Embed query\n",
    "            query_vector = self.embeddings.embed_query(task.query)\n",
    "\n",
    "            # Query text and image collections (session-scoped when available)\n",
    "            where_filter = {\"session_id\": session_id} if session_id in self.session_memory else None\n",
    "\n",
    "            text_results = self.text_collection.query(\n",
    "                query_embeddings=[query_vector],\n",
    "                n_results=5,\n",
    "                where=where_filter\n",
    "            )\n",
    "\n",
    "            image_results = self.image_collection.query(\n",
    "                query_embeddings=[query_vector],\n",
    "                n_results=3,\n",
    "                where=where_filter\n",
    "            )\n",
    "\n",
    "            all_docs = []\n",
    "            sources = []\n",
    "\n",
    "            # text_results structure: {'ids': [...], 'documents': [[...]], 'metadatas': [[...]], ...}\n",
    "            if text_results.get('documents') and text_results['documents'][0]:\n",
    "                for i, doc in enumerate(text_results['documents'][0]):\n",
    "                    all_docs.append(doc)\n",
    "                    meta = text_results.get('metadatas', [[]])[0]\n",
    "                    if i < len(meta):\n",
    "                        sources.append(meta[i].get('file_name', 'Unknown'))\n",
    "\n",
    "            if image_results.get('documents') and image_results['documents'][0]:\n",
    "                for i, doc in enumerate(image_results['documents'][0]):\n",
    "                    all_docs.append(doc)\n",
    "                    meta = image_results.get('metadatas', [[]])[0]\n",
    "                    if i < len(meta):\n",
    "                        sources.append(meta[i].get('file_name', 'Unknown'))\n",
    "\n",
    "            if not all_docs:\n",
    "                return AgentResponse(\n",
    "                    agent_type=AgentType.RESEARCHER,\n",
    "                    content=\"No relevant documents found in the knowledge base.\",\n",
    "                    confidence=0.0,\n",
    "                    sources=[],\n",
    "                    reasoning=\"Empty KB or no matches\"\n",
    "                )\n",
    "\n",
    "            context = \"\\n\\n\".join(all_docs[:8])  # limit context size\n",
    "\n",
    "            research_prompt = f\"\"\"\n",
    "As a Research Agent, analyze the following documents to answer the query: \"{task.query}\"\n",
    "\n",
    "Context from documents:\n",
    "{context}\n",
    "\n",
    "Your tasks:\n",
    "1) Extract key information relevant to the query\n",
    "2) Identify facts, figures, and important concepts\n",
    "3) Note gaps in information\n",
    "4) Assess reliability of the sources\n",
    "5) Provide a confidence score (0-1)\n",
    "\n",
    "Format the result clearly.\n",
    "\"\"\"\n",
    "            resp = self.gemini_model.generate_content(research_prompt)\n",
    "            confidence = 0.8 if len(all_docs) >= 3 else 0.6 if len(all_docs) >= 1 else 0.3\n",
    "\n",
    "            return AgentResponse(\n",
    "                agent_type=AgentType.RESEARCHER,\n",
    "                content=resp.text,\n",
    "                confidence=confidence,\n",
    "                sources=list(set(sources)),\n",
    "                reasoning=f\"Analyzed {len(all_docs)} documents from {len(set(sources))} sources\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            return AgentResponse(\n",
    "                agent_type=AgentType.RESEARCHER,\n",
    "                content=f\"Research error: {str(e)}\",\n",
    "                confidence=0.0,\n",
    "                sources=[],\n",
    "                reasoning=\"Agent execution failed\"\n",
    "            )\n",
    "\n",
    "    async def synthesis_agent(self, research_response: AgentResponse, query: str) -> AgentResponse:\n",
    "        try:\n",
    "            synthesis_prompt = f\"\"\"\n",
    "As a Synthesis Agent, create a comprehensive answer to: \"{query}\"\n",
    "\n",
    "Research findings:\n",
    "{research_response.content}\n",
    "\n",
    "Your tasks:\n",
    "1) Synthesize into a coherent, well-structured answer\n",
    "2) Include relevant context and connections\n",
    "3) Ensure the answer directly addresses the query\n",
    "\"\"\"\n",
    "            resp = self.gemini_model.generate_content(synthesis_prompt)\n",
    "\n",
    "            return AgentResponse(\n",
    "                agent_type=AgentType.SYNTHESIZER,\n",
    "                content=resp.text,\n",
    "                confidence=min(research_response.confidence + 0.1, 1.0),\n",
    "                sources=research_response.sources,\n",
    "                reasoning=\"Synthesized information from research findings\",\n",
    "                follow_up_needed=len(research_response.sources) < 2\n",
    "            )\n",
    "        except Exception as e:\n",
    "            return AgentResponse(\n",
    "                agent_type=AgentType.SYNTHESIZER,\n",
    "                content=f\"Synthesis error: {str(e)}\",\n",
    "                confidence=0.0,\n",
    "                sources=research_response.sources,\n",
    "                reasoning=\"Synthesis agent execution failed\"\n",
    "            )\n",
    "\n",
    "    async def fact_checker_agent(self, synthesis_response: AgentResponse, query: str) -> AgentResponse:\n",
    "        try:\n",
    "            fact_check_prompt = f\"\"\"\n",
    "As a Fact Checker Agent, review the synthesized answer for accuracy and consistency.\n",
    "\n",
    "Original Query: \"{query}\"\n",
    "\n",
    "Synthesized Answer:\n",
    "{synthesis_response.content}\n",
    "\n",
    "Tasks:\n",
    "1) Check internal consistency\n",
    "2) Verify claims against the provided sources\n",
    "3) Identify contradictions or uncertainties\n",
    "4) Suggest corrections if needed\n",
    "5) Provide a final confidence score\n",
    "\n",
    "Return sections: VERIFIED:, UNCERTAIN:, CORRECTIONS:, CONFIDENCE:\n",
    "\"\"\"\n",
    "            resp = self.gemini_model.generate_content(fact_check_prompt)\n",
    "\n",
    "            adjusted_confidence = synthesis_response.confidence\n",
    "            if \"UNCERTAIN\" in resp.text:\n",
    "                adjusted_confidence -= 0.2\n",
    "            if \"CORRECTIONS\" in resp.text:\n",
    "                adjusted_confidence -= 0.1\n",
    "            adjusted_confidence = max(adjusted_confidence, 0.1)\n",
    "\n",
    "            return AgentResponse(\n",
    "                agent_type=AgentType.FACT_CHECKER,\n",
    "                content=resp.text,\n",
    "                confidence=adjusted_confidence,\n",
    "                sources=synthesis_response.sources,\n",
    "                reasoning=\"Fact-checked synthesized response for accuracy\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            return AgentResponse(\n",
    "                agent_type=AgentType.FACT_CHECKER,\n",
    "                content=synthesis_response.content,\n",
    "                confidence=max(synthesis_response.confidence - 0.1, 0.0),\n",
    "                sources=synthesis_response.sources,\n",
    "                reasoning=\"Fact-checking failed, returning synthesis\"\n",
    "            )\n",
    "\n",
    "    async def follow_up_agent(self, final_response: AgentResponse, query: str) -> AgentResponse:\n",
    "        try:\n",
    "            follow_up_prompt = f\"\"\"\n",
    "As a Follow-up Agent, generate 3-5 relevant follow-up questions for the user.\n",
    "\n",
    "Original Query: \"{query}\"\n",
    "\n",
    "Answer Provided:\n",
    "{final_response.content}\n",
    "\n",
    "Make the questions specific, actionable, and aimed at exploring gaps or deeper aspects.\n",
    "\"\"\"\n",
    "            resp = self.gemini_model.generate_content(follow_up_prompt)\n",
    "            return AgentResponse(\n",
    "                agent_type=AgentType.FOLLOW_UP,\n",
    "                content=resp.text,\n",
    "                confidence=final_response.confidence,\n",
    "                sources=final_response.sources,\n",
    "                reasoning=\"Generated contextual follow-up questions\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            return AgentResponse(\n",
    "                agent_type=AgentType.FOLLOW_UP,\n",
    "                content=\"No follow-up questions generated due to error.\",\n",
    "                confidence=0.0,\n",
    "                sources=[],\n",
    "                reasoning=\"Follow-up agent execution failed\"\n",
    "            )\n",
    "\n",
    "    # ------------------------------\n",
    "    # Coordinator & final response formatting\n",
    "    # ------------------------------\n",
    "    async def coordinator_agent(self, query: str, session_id: str = \"default\") -> Dict[str, Any]:\n",
    "        start_time = datetime.now()\n",
    "        try:\n",
    "            research_task = ResearchTask(query=query, context=\"User question requiring comprehensive analysis\", agent_type=AgentType.RESEARCHER)\n",
    "\n",
    "            research_response = await self.research_agent(research_task, session_id)\n",
    "            synthesis_response = await self.synthesis_agent(research_response, query)\n",
    "            fact_checked_response = await self.fact_checker_agent(synthesis_response, query)\n",
    "            follow_up_response = await self.follow_up_agent(fact_checked_response, query)\n",
    "\n",
    "            # Store agent interactions in memory\n",
    "            agent_session_key = f\"{session_id}_agents\"\n",
    "            if agent_session_key not in self.agent_memory:\n",
    "                self.agent_memory[agent_session_key] = []\n",
    "\n",
    "            interaction = {\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"query\": query,\n",
    "                \"research\": research_response.__dict__,\n",
    "                \"synthesis\": synthesis_response.__dict__,\n",
    "                \"fact_check\": fact_checked_response.__dict__,\n",
    "                \"follow_up\": follow_up_response.__dict__,\n",
    "                \"processing_time\": (datetime.now() - start_time).total_seconds()\n",
    "            }\n",
    "            self.agent_memory[agent_session_key].append(interaction)\n",
    "\n",
    "            final_answer = self._create_final_response(\n",
    "                fact_checked_response,\n",
    "                follow_up_response,\n",
    "                research_response.sources,\n",
    "                interaction[\"processing_time\"]\n",
    "            )\n",
    "\n",
    "            return {\n",
    "                \"answer\": final_answer,\n",
    "                \"confidence\": fact_checked_response.confidence,\n",
    "                \"sources\": fact_checked_response.sources,\n",
    "                \"agent_insights\": {\n",
    "                    \"research\": research_response.reasoning,\n",
    "                    \"synthesis\": synthesis_response.reasoning,\n",
    "                    \"fact_check\": fact_checked_response.reasoning,\n",
    "                    \"follow_up\": follow_up_response.reasoning\n",
    "                },\n",
    "                \"processing_time\": interaction[\"processing_time\"],\n",
    "                \"follow_up_questions\": follow_up_response.content\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"answer\": f\"Coordinator error: {str(e)}\",\n",
    "                \"confidence\": 0.0,\n",
    "                \"sources\": [],\n",
    "                \"agent_insights\": {\"error\": str(e)},\n",
    "                \"processing_time\": (datetime.now() - start_time).total_seconds(),\n",
    "                \"follow_up_questions\": \"Unable to generate follow-up questions due to error.\"\n",
    "            }\n",
    "\n",
    "    def _create_final_response(self, fact_checked: AgentResponse, follow_up: AgentResponse,\n",
    "                               sources: List[str], processing_time: float) -> str:\n",
    "        \"\"\"Format the final response for the user (cleaned, with confidence & sources)\"\"\"\n",
    "        answer_lines = fact_checked.content.split('\\n')\n",
    "        main_answer = \"\"\n",
    "        for line in answer_lines:\n",
    "            if not any(keyword in line.upper() for keyword in ['VERIFIED:', 'UNCERTAIN:', 'CORRECTIONS:', 'CONFIDENCE:']):\n",
    "                main_answer += line + \"\\n\"\n",
    "\n",
    "        if not main_answer.strip():\n",
    "            main_answer = fact_checked.content\n",
    "\n",
    "        stars_count = min(max(int(round(fact_checked.confidence * 5)), 0), 5)\n",
    "        confidence_stars = \"‚òÖ\" * stars_count + \"‚òÜ\" * (5 - stars_count)\n",
    "\n",
    "        final_response = f\"\"\"{main_answer.strip()}\n",
    "\n",
    "üéØ Confidence: {confidence_stars} ({fact_checked.confidence:.1%})\n",
    "\n",
    "üìö Sources: {', '.join(set(sources)) if sources else 'No sources found'}\n",
    "\n",
    "ü§î Follow-up Questions:\n",
    "{follow_up.content}\n",
    "\n",
    "‚ö° Processing Time: {processing_time:.2f} seconds\n",
    "ü§ñ Powered by: Multi-Agent RAG (Gemini + OpenAI embeddings)\"\"\"\n",
    "        return final_response\n",
    "\n",
    "    # ------------------------------\n",
    "    # Ingestion: add document / image\n",
    "    # ------------------------------\n",
    "    def add_document(self, file_path: str, file_name: str, session_id: str = \"default\") -> str:\n",
    "        \"\"\"Add a document or image to the knowledge base with embeddings & metadata.\"\"\"\n",
    "        try:\n",
    "            file_extension = file_name.lower().split('.')[-1]\n",
    "\n",
    "            # Text documents\n",
    "            if file_extension in ['pdf', 'docx', 'pptx', 'txt']:\n",
    "                content = self.extract_text_from_file(file_path, file_extension)\n",
    "                if not content or content.startswith(\"Error\"):\n",
    "                    return f\"‚ùå Failed to extract content from {file_name}: {content}\"\n",
    "\n",
    "                # Split into chunks\n",
    "                chunks = self.text_splitter.split_text(content)\n",
    "                if not chunks:\n",
    "                    return f\"‚ùå No chunks created for {file_name}\"\n",
    "\n",
    "                # Create embeddings for all chunks in batch\n",
    "                try:\n",
    "                    chunk_embeddings = self.embeddings.embed_documents(chunks)\n",
    "                except Exception:\n",
    "                    # fallback to individual queries if embed_documents not available\n",
    "                    chunk_embeddings = [self.embeddings.embed_query(chunk) for chunk in chunks]\n",
    "\n",
    "                for i, chunk in enumerate(chunks):\n",
    "                    chunk_id = f\"{file_name}_{i}_{datetime.now().timestamp()}\"\n",
    "                    metadata = {\n",
    "                        \"file_name\": file_name,\n",
    "                        \"file_type\": file_extension,\n",
    "                        \"chunk_index\": i,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"timestamp\": datetime.now().isoformat(),\n",
    "                        \"content_length\": len(chunk),\n",
    "                        \"agent_processed\": True,\n",
    "                        \"chunk_summary\": (chunk[:100] + \"...\") if len(chunk) > 100 else chunk\n",
    "                    }\n",
    "\n",
    "                    emb = chunk_embeddings[i] if i < len(chunk_embeddings) else self.embeddings.embed_query(chunk)\n",
    "                    self.text_collection.add(\n",
    "                        embeddings=[emb],\n",
    "                        documents=[chunk],\n",
    "                        metadatas=[metadata],\n",
    "                        ids=[chunk_id]\n",
    "                    )\n",
    "\n",
    "                # update session memory\n",
    "                self.session_memory.setdefault(session_id, []).append({\n",
    "                    \"file_name\": file_name,\n",
    "                    \"file_type\": file_extension,\n",
    "                    \"chunks_count\": len(chunks),\n",
    "                    \"timestamp\": datetime.now().isoformat(),\n",
    "                    \"agent_ready\": True\n",
    "                })\n",
    "\n",
    "                return f\"‚úÖ Successfully processed {file_name} ({len(chunks)} chunks) - Agent Ready\"\n",
    "\n",
    "            # Images\n",
    "            elif file_extension in ['jpg', 'jpeg', 'png', 'gif', 'bmp']:\n",
    "                analysis = self.process_image_with_gemini(file_path)\n",
    "                if not analysis or analysis.startswith(\"Error\"):\n",
    "                    return f\"‚ùå Failed to process image {file_name}: {analysis}\"\n",
    "\n",
    "                # embedding for image analysis text\n",
    "                try:\n",
    "                    emb = self.embeddings.embed_query(analysis)\n",
    "                except Exception:\n",
    "                    emb = self.embeddings.embed_documents([analysis])[0]\n",
    "\n",
    "                doc_id = f\"{file_name}_{datetime.now().timestamp()}\"\n",
    "                metadata = {\n",
    "                    \"file_name\": file_name,\n",
    "                    \"file_type\": \"image\",\n",
    "                    \"session_id\": session_id,\n",
    "                    \"timestamp\": datetime.now().isoformat(),\n",
    "                    \"agent_processed\": True,\n",
    "                    \"image_analysis\": analysis[:200] + \"...\" if len(analysis) > 200 else analysis\n",
    "                }\n",
    "\n",
    "                self.image_collection.add(\n",
    "                    embeddings=[emb],\n",
    "                    documents=[analysis],\n",
    "                    metadatas=[metadata],\n",
    "                    ids=[doc_id]\n",
    "                )\n",
    "\n",
    "                self.session_memory.setdefault(session_id, []).append({\n",
    "                    \"file_name\": file_name,\n",
    "                    \"file_type\": \"image\",\n",
    "                    \"timestamp\": datetime.now().isoformat(),\n",
    "                    \"agent_ready\": True\n",
    "                })\n",
    "\n",
    "                return f\"‚úÖ Successfully processed image {file_name} - Agent Ready\"\n",
    "\n",
    "            else:\n",
    "                return f\"‚ùå Unsupported file type: {file_extension}\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"‚ùå Error processing {file_name}: {str(e)}\"\n",
    "\n",
    "    # ------------------------------\n",
    "    # Session & agent info\n",
    "    # ------------------------------\n",
    "    def get_session_info(self, session_id: str = \"default\") -> str:\n",
    "        if session_id not in self.session_memory:\n",
    "            return \"No documents uploaded in this session.\"\n",
    "\n",
    "        docs = self.session_memory[session_id]\n",
    "        info = f\"üìÅ Session Documents ({len(docs)} files):\\n\\n\"\n",
    "        for doc in docs:\n",
    "            info += f\"‚Ä¢ {doc['file_name']} ({doc['file_type']}) - {doc['timestamp'][:19]}\\n\"\n",
    "            if 'chunks_count' in doc:\n",
    "                info += f\"  ‚îî‚îÄ‚îÄ {doc['chunks_count']} text chunks\\n\"\n",
    "            if doc.get('agent_ready'):\n",
    "                info += f\"  ‚îî‚îÄ‚îÄ ü§ñ Agent-ready processing ‚úì\\n\"\n",
    "\n",
    "        agent_key = f\"{session_id}_agents\"\n",
    "        if agent_key in self.agent_memory:\n",
    "            interactions = len(self.agent_memory[agent_key])\n",
    "            avg_time = sum(i[\"processing_time\"] for i in self.agent_memory[agent_key]) / interactions\n",
    "            info += f\"\\nü§ñ Agent Statistics:\\n‚Ä¢ Total queries processed: {interactions}\\n‚Ä¢ Average processing time: {avg_time:.2f} seconds\\n\"\n",
    "\n",
    "        return info\n",
    "\n",
    "    def get_agent_insights(self, session_id: str = \"default\") -> str:\n",
    "        agent_key = f\"{session_id}_agents\"\n",
    "        if agent_key not in self.agent_memory or not self.agent_memory[agent_key]:\n",
    "            return \"No agent interactions recorded for this session.\"\n",
    "\n",
    "        latest = self.agent_memory[agent_key][-1]\n",
    "        insights = f\"üîç Latest Agent Analysis:\\n\\n\"\n",
    "        insights += f\"Query: {latest['query']}\\n\\n\"\n",
    "        insights += f\"üî¨ Research Agent: {latest['research']['reasoning']}\\n\"\n",
    "        insights += f\"  ‚îî‚îÄ‚îÄ Confidence: {latest['research']['confidence']:.1%}\\n\"\n",
    "        insights += f\"  ‚îî‚îÄ‚îÄ Sources: {len(latest['research']['sources'])}\\n\\n\"\n",
    "        insights += f\"üß© Synthesis Agent: {latest['synthesis']['reasoning']}\\n\"\n",
    "        insights += f\"  ‚îî‚îÄ‚îÄ Confidence: {latest['synthesis']['confidence']:.1%}\\n\\n\"\n",
    "        insights += f\"‚úÖ Fact Checker: {latest['fact_check']['reasoning']}\\n\"\n",
    "        insights += f\"  ‚îî‚îÄ‚îÄ Final Confidence: {latest['fact_check']['confidence']:.1%}\\n\\n\"\n",
    "        insights += f\"‚ùì Follow-up Agent: {latest['follow_up']['reasoning']}\\n\\n\"\n",
    "        insights += f\"‚ö° Total Processing Time: {latest['processing_time']:.2f} seconds\\n\"\n",
    "        return insights\n",
    "\n",
    "# ------------------------------\n",
    "# Global instance & UI wrappers\n",
    "# ------------------------------\n",
    "agentic_rag_system: Optional[AgenticRAG] = None\n",
    "\n",
    "def initialize_agentic_system(gemini_key: str, openai_key: str) -> str:\n",
    "    \"\"\"Initialize the Agentic RAG system with Gemini + OpenAI keys\"\"\"\n",
    "    global agentic_rag_system\n",
    "    if not gemini_key or not openai_key:\n",
    "        return \"‚ùå Please provide both Gemini and OpenAI API keys.\"\n",
    "    try:\n",
    "        agentic_rag_system = AgenticRAG(gemini_key.strip(), openai_key.strip())\n",
    "        return \"‚úÖ Agentic RAG System initialized successfully! Multi-agent workflow ready.\"\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error initializing agentic system: {str(e)}\"\n",
    "\n",
    "def upload_document_agentic(files, session_id: str = \"default\") -> str:\n",
    "    \"\"\"Handle document upload from Gradio (files is a list of uploaded files)\"\"\"\n",
    "    if agentic_rag_system is None:\n",
    "        return \"‚ùå Please initialize the agentic system with your API keys first.\"\n",
    "\n",
    "    if not files:\n",
    "        return \"‚ùå No files uploaded.\"\n",
    "\n",
    "    results = []\n",
    "    for f in files:\n",
    "        # Gradio file object typically provides a .name path to temp file\n",
    "        file_path = getattr(f, \"name\", None) or f\n",
    "        file_name = os.path.basename(file_path)\n",
    "        try:\n",
    "            result = agentic_rag_system.add_document(file_path, file_name, session_id)\n",
    "        except Exception as e:\n",
    "            result = f\"‚ùå Error processing {file_name}: {str(e)}\"\n",
    "        results.append(result)\n",
    "\n",
    "    return \"\\n\".join(results)\n",
    "\n",
    "async def ask_question_agentic(question: str, session_id: str = \"default\") -> str:\n",
    "    if agentic_rag_system is None:\n",
    "        return \"‚ùå Please initialize the agentic system with your API keys first.\"\n",
    "    if not question:\n",
    "        return \"‚ùå Please ask a question.\"\n",
    "\n",
    "    response = await agentic_rag_system.coordinator_agent(question, session_id)\n",
    "    return response[\"answer\"]\n",
    "\n",
    "def ask_question_sync(question: str, session_id: str = \"default\") -> str:\n",
    "    try:\n",
    "        loop = asyncio.new_event_loop()\n",
    "        asyncio.set_event_loop(loop)\n",
    "        result = loop.run_until_complete(ask_question_agentic(question, session_id))\n",
    "        loop.close()\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error processing question: {str(e)}\"\n",
    "\n",
    "def get_session_status_agentic(session_id: str = \"default\") -> str:\n",
    "    if agentic_rag_system is None:\n",
    "        return \"‚ùå Agentic system not initialized\"\n",
    "    return agentic_rag_system.get_session_info(session_id)\n",
    "\n",
    "def get_agent_insights_ui(session_id: str = \"default\") -> str:\n",
    "    if agentic_rag_system is None:\n",
    "        return \"‚ùå Agentic system not initialized\"\n",
    "    return agentic_rag_system.get_agent_insights(session_id)\n",
    "\n",
    "# ------------------------------\n",
    "# Gradio UI\n",
    "# ------------------------------\n",
    "def create_agentic_gradio_interface():\n",
    "    with gr.Blocks(title=\"Enterprise Knowledge Assistant - Phase 2 (Agentic)\", theme=gr.themes.Soft()) as demo:\n",
    "        gr.Markdown(\"\"\"\n",
    "# üß†ü§ñ Enterprise Knowledge Assistant (Phase 2 - Agentic)\n",
    "\n",
    "**Multi-Agent RAG System**\n",
    "\n",
    "- Gemini ‚Üí reasoning, synthesis, fact-check, follow-ups  \n",
    "- OpenAI ‚Üí embeddings for retrieval\n",
    "        \"\"\")\n",
    "\n",
    "        with gr.Tab(\"üîß Setup\"):\n",
    "            gr.Markdown(\"### Initialize the Agentic RAG System\")\n",
    "            gemini_input = gr.Textbox(label=\"Gemini API Key\", placeholder=\"Enter Gemini API key\", type=\"password\")\n",
    "            openai_input = gr.Textbox(label=\"OpenAI API Key\", placeholder=\"Enter OpenAI API key\", type=\"password\")\n",
    "            init_btn = gr.Button(\"Initialize Agentic System\", variant=\"primary\")\n",
    "            init_status = gr.Textbox(label=\"Status\", interactive=False)\n",
    "            init_btn.click(fn=initialize_agentic_system, inputs=[gemini_input, openai_input], outputs=[init_status])\n",
    "\n",
    "        with gr.Tab(\"üìÅ Upload Documents\"):\n",
    "            gr.Markdown(\"### Upload documents/images for ingestion\")\n",
    "            session_input = gr.Textbox(label=\"Session ID\", value=\"default\", placeholder=\"Session ID (optional)\")\n",
    "            file_upload = gr.Files(label=\"Upload files\", file_count=\"multiple\",\n",
    "                                   file_types=[\".pdf\", \".docx\", \".pptx\", \".txt\", \".jpg\", \".jpeg\", \".png\", \".gif\", \".bmp\"])\n",
    "            upload_btn = gr.Button(\"Process Documents (Agentic)\", variant=\"primary\")\n",
    "            upload_status = gr.Textbox(label=\"Upload Status\", interactive=False, lines=6)\n",
    "            upload_btn.click(fn=upload_document_agentic, inputs=[file_upload, session_input], outputs=[upload_status])\n",
    "\n",
    "        with gr.Tab(\"ü§ñ Ask Questions (Multi-Agent)\"):\n",
    "            gr.Markdown(\"### Query your knowledge base\")\n",
    "            session_query = gr.Textbox(label=\"Session ID\", value=\"default\")\n",
    "            question_input = gr.Textbox(label=\"Your Question\", placeholder=\"Ask about uploaded documents...\", lines=3)\n",
    "            ask_btn = gr.Button(\"Get Multi-Agent Answer\", variant=\"primary\")\n",
    "            answer_output = gr.Textbox(label=\"Agent-Generated Answer\", interactive=False, lines=15)\n",
    "            ask_btn.click(fn=ask_question_sync, inputs=[question_input, session_query], outputs=[answer_output])\n",
    "\n",
    "        with gr.Tab(\"üîç Agent Insights\"):\n",
    "            gr.Markdown(\"### Agent analysis & reasoning\")\n",
    "            insights_session_input = gr.Textbox(label=\"Session ID\", value=\"default\")\n",
    "            insights_btn = gr.Button(\"Get Agent Insights\", variant=\"secondary\")\n",
    "            insights_output = gr.Textbox(label=\"Agent Reasoning and Analysis\", interactive=False, lines=12)\n",
    "            insights_btn.click(fn=get_agent_insights_ui, inputs=[insights_session_input], outputs=[insights_output])\n",
    "\n",
    "        with gr.Tab(\"üìä Session Info\"):\n",
    "            gr.Markdown(\"### Session status & memory\")\n",
    "            session_status_input = gr.Textbox(label=\"Session ID\", value=\"default\")\n",
    "            status_btn = gr.Button(\"Check Status\")\n",
    "            status_output = gr.Textbox(label=\"Session Information\", interactive=False, lines=10)\n",
    "            status_btn.click(fn=get_session_status_agentic, inputs=[session_status_input], outputs=[status_output])\n",
    "\n",
    "    return demo\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo = create_agentic_gradio_interface()\n",
    "    demo.launch(server_name=\"0.0.0.0\", server_port=7862, share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb6f3f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
